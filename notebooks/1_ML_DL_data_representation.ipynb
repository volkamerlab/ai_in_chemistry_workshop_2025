{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://gist.github.com/Afnan-Sultan/111fb1376659d526f8b57ca45dd8581a#file-session_1-ipynb",
     "timestamp": 1758532058908
    }
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Inside the heart of machine learning!\n",
    "\n",
    "**Instructor**: Afnan Sultan, Volkamer Lab, Saarland University (s8afsult@uni-saarland.de)\n",
    "\n",
    "\n",
    "**Course date**: 22nd September 2025\n",
    "\n",
    "\n",
    "## Find the quiz link!\n",
    "\n",
    "In this session we will have an interactive quiz, so please join from your laptop or phone\n",
    "\n",
    "Link: https://www.menti.com/alo5wi2b2iu9\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/volkamerlab/ai_in_chemistry_workshop_2025/main/notebooks/ml_quiz.png\" width=\"400\">\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Important Note\n",
    "\n",
    "If you're running this notebook on Google Colab, it will run a lot faster if you set the runtime type to **T4 GPU**.\n",
    "You can do this from the **Runtime** menu.\n",
    "\n",
    "Runtime->Change Runtime Type->T4 GPU"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T11:11:34.278319Z",
     "start_time": "2025-09-22T11:08:18.800479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install PyTDC\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "!pip install torch-geometric torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "# !pip install torch-geometric torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-1.13.0+cu116.html"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyTDC\r\n",
      "  Downloading pytdc-1.1.15.tar.gz (154 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m154.2/154.2 kB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting accelerate==0.33.0 (from PyTDC)\r\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting dataclasses<1.0,>=0.6 (from PyTDC)\r\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting datasets<2.20.0 (from PyTDC)\r\n",
      "  Downloading datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting evaluate==0.4.2 (from PyTDC)\r\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Collecting fuzzywuzzy<1.0,>=0.18.0 (from PyTDC)\r\n",
      "  Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Collecting huggingface_hub<1.0,>=0.20.3 (from PyTDC)\r\n",
      "  Downloading huggingface_hub-0.35.0-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.4 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from PyTDC) (1.26.4)\r\n",
      "Collecting openpyxl<4.0.0,>=3.0.10 (from PyTDC)\r\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting pandas<3.0.0,>=2.1.4 (from PyTDC)\r\n",
      "  Downloading pandas-2.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (91 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m91.2/91.2 kB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from PyTDC) (2.31.0)\r\n",
      "Requirement already satisfied: scikit-learn>=1.2.2 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from PyTDC) (1.3.2)\r\n",
      "Collecting seaborn<1.0.0,>=0.12.2 (from PyTDC)\r\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from PyTDC) (4.65.0)\r\n",
      "Collecting transformers<4.51.0,>=4.43.0 (from PyTDC)\r\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\r\n",
      "INFO: pip is looking at multiple versions of pytdc to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting PyTDC\r\n",
      "  Downloading pytdc-1.1.14.tar.gz (151 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m151.3/151.3 kB\u001B[0m \u001B[31m8.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting scikit-learn==1.2.2 (from PyTDC)\r\n",
      "  Downloading scikit-learn-1.2.2.tar.gz (7.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.3/7.3 MB\u001B[0m \u001B[31m21.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting transformers==4.43.4 (from PyTDC)\r\n",
      "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.7/43.7 kB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting PyTDC\r\n",
      "  Downloading PyTDC-1.1.13.tar.gz (151 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m151.2/151.2 kB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Downloading pytdc-1.1.12.tar.gz (151 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m151.2/151.2 kB\u001B[0m \u001B[31m8.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Downloading pytdc-1.1.11.tar.gz (151 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m151.1/151.1 kB\u001B[0m \u001B[31m8.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Downloading pytdc-1.1.10.tar.gz (151 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m151.1/151.1 kB\u001B[0m \u001B[31m9.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Downloading pytdc-1.1.9.tar.gz (151 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m151.1/151.1 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Downloading pytdc-1.1.8.tar.gz (151 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m151.2/151.2 kB\u001B[0m \u001B[31m9.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hINFO: pip is still looking at multiple versions of pytdc to determine which version is compatible with other requirements. This could take a while.\r\n",
      "  Downloading pytdc-1.1.7.tar.gz (151 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m151.2/151.2 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Downloading pytdc-1.1.6.tar.gz (151 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m151.3/151.3 kB\u001B[0m \u001B[31m10.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting biopython<2.0,>=1.78 (from PyTDC)\r\n",
      "  Downloading biopython-1.85-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\r\n",
      "Collecting PyTDC\r\n",
      "  Downloading pytdc-1.1.5.tar.gz (151 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m151.2/151.2 kB\u001B[0m \u001B[31m12.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Downloading pytdc-1.1.4.tar.gz (151 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m151.3/151.3 kB\u001B[0m \u001B[31m11.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting moleculeace==3.0.0 (from PyTDC)\r\n",
      "  Downloading MoleculeACE-3.0.0-py3-none-any.whl.metadata (549 bytes)\r\n",
      "Collecting mygene<4.0.0,>=3.2.2 (from PyTDC)\r\n",
      "  Downloading mygene-3.2.2-py2.py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting PyTDC\r\n",
      "  Downloading pytdc-1.1.3.tar.gz (148 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m148.2/148.2 kB\u001B[0m \u001B[31m13.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\r\n",
      "  Downloading pytdc-1.1.2.tar.gz (146 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m146.6/146.6 kB\u001B[0m \u001B[31m12.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting datasets==2.20.0 (from PyTDC)\r\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting PyTDC\r\n",
      "  Downloading pytdc-1.1.1.tar.gz (146 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m146.8/146.8 kB\u001B[0m \u001B[31m8.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Downloading pytdc-1.1.0.tar.gz (145 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m145.6/145.6 kB\u001B[0m \u001B[31m8.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Downloading pytdc-1.0.7.tar.gz (144 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m144.4/144.4 kB\u001B[0m \u001B[31m8.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Downloading pytdc-1.0.6.tar.gz (143 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m143.7/143.7 kB\u001B[0m \u001B[31m7.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Downloading PyTDC-1.0.0.tar.gz (141 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m141.5/141.5 kB\u001B[0m \u001B[31m8.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting cellxgene-census<2.0.0,>=1.10.2 (from PyTDC)\r\n",
      "  Downloading cellxgene_census-1.17.0-py3-none-any.whl.metadata (5.2 kB)\r\n",
      "Collecting gget<1.0.0,>=0.28.4 (from PyTDC)\r\n",
      "  Downloading gget-0.29.3-py3-none-any.whl.metadata (7.9 kB)\r\n",
      "Collecting pydantic<3.0.0,>=2.6.3 (from PyTDC)\r\n",
      "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m68.4/68.4 kB\u001B[0m \u001B[31m6.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting rdkit<2024.3.1,>=2023.9.5 (from PyTDC)\r\n",
      "  Downloading rdkit-2023.9.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.9 kB)\r\n",
      "Collecting tiledbsoma<2.0.0,>=1.7.2 (from PyTDC)\r\n",
      "  Downloading tiledbsoma-1.17.1-cp312-cp312-macosx_13_0_arm64.whl.metadata (7.0 kB)\r\n",
      "Collecting yapf<1.0.0,>=0.40.2 (from PyTDC)\r\n",
      "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.8/46.8 kB\u001B[0m \u001B[31m5.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: scipy>=1.3.2 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from scikit-learn==1.2.2->PyTDC) (1.13.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from scikit-learn==1.2.2->PyTDC) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from scikit-learn==1.2.2->PyTDC) (3.5.0)\r\n",
      "Collecting anndata (from cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading anndata-0.12.2-py3-none-any.whl.metadata (9.6 kB)\r\n",
      "Collecting typing_extensions (from cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting s3fs>=2021.06.1 (from cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading s3fs-2025.9.0-py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting ipython (from gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading ipython-9.5.0-py3-none-any.whl.metadata (4.4 kB)\r\n",
      "Collecting matplotlib (from gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading matplotlib-3.10.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\r\n",
      "Collecting mysql-connector-python>=8.0.32 (from gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading mysql_connector_python-9.4.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (7.5 kB)\r\n",
      "Collecting beautifulsoup4>=4.10.0 (from gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading beautifulsoup4-4.13.5-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting ipywidgets (from gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting lxml (from gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading lxml-6.0.2-cp312-cp312-macosx_10_13_universal2.whl.metadata (3.6 kB)\r\n",
      "Collecting filelock (from huggingface_hub<1.0,>=0.20.3->PyTDC)\r\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub<1.0,>=0.20.3->PyTDC)\r\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from huggingface_hub<1.0,>=0.20.3->PyTDC) (23.2)\r\n",
      "Collecting pyyaml>=5.1 (from huggingface_hub<1.0,>=0.20.3->PyTDC)\r\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\r\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub<1.0,>=0.20.3->PyTDC)\r\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\r\n",
      "Collecting biothings-client>=0.2.6 (from mygene<4.0.0,>=3.2.2->PyTDC)\r\n",
      "  Downloading biothings_client-0.4.1-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting et-xmlfile (from openpyxl<4.0.0,>=3.0.10->PyTDC)\r\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Collecting python-dateutil>=2.8.2 (from pandas<3.0.0,>=2.1.4->PyTDC)\r\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\r\n",
      "Collecting pytz>=2020.1 (from pandas<3.0.0,>=2.1.4->PyTDC)\r\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0.0,>=2.1.4->PyTDC)\r\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.6.3->PyTDC)\r\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.6.3->PyTDC)\r\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\r\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.6.3->PyTDC)\r\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Collecting Pillow (from rdkit<2024.3.1,>=2023.9.5->PyTDC)\r\n",
      "  Downloading pillow-11.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.0 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->PyTDC) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->PyTDC) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->PyTDC) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->PyTDC) (2024.2.2)\r\n",
      "Collecting attrs>=22.2 (from tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting more-itertools (from tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\r\n",
      "Collecting pyarrow (from tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\r\n",
      "Collecting scanpy>=1.9.2 (from tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Downloading scanpy-1.11.4-py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Collecting somacore==1.0.28 (from tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Downloading somacore-1.0.28-py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting pyarrow-hotfix (from somacore==1.0.28->tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Collecting shapely (from somacore==1.0.28->tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Downloading shapely-2.1.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from yapf<1.0.0,>=0.40.2->PyTDC) (3.10.0)\r\n",
      "Collecting array-api-compat>=1.7.1 (from anndata->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading array_api_compat-1.12.0-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting h5py>=3.8 (from anndata->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading h5py-3.14.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.7 kB)\r\n",
      "Collecting legacy-api-wrap (from anndata->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading legacy_api_wrap-1.4.1-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting natsort (from anndata->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\r\n",
      "Collecting packaging>=20.9 (from huggingface_hub<1.0,>=0.20.3->PyTDC)\r\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting zarr!=3.0.*,>=2.18.7 (from anndata->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading zarr-3.1.3-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4>=4.10.0->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting httpx>=0.22.0 (from biothings-client>=0.2.6->mygene<4.0.0,>=3.2.2->PyTDC)\r\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\r\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\r\n",
      "Collecting cycler>=0.10 (from matplotlib->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading fonttools-4.60.0-cp312-cp312-macosx_10_13_universal2.whl.metadata (111 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m111.6/111.6 kB\u001B[0m \u001B[31m8.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting kiwisolver>=1.3.1 (from matplotlib->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.3 kB)\r\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->PyTDC)\r\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs>=2021.06.1->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading aiobotocore-2.24.2-py3-none-any.whl.metadata (25 kB)\r\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from s3fs>=2021.06.1->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading aiohttp-3.12.15-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\r\n",
      "Collecting networkx>=2.7.1 (from scanpy>=1.9.2->tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Collecting numba>=0.57.1 (from scanpy>=1.9.2->tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Downloading numba-0.62.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.8 kB)\r\n",
      "Collecting patsy!=1.0.0 (from scanpy>=1.9.2->tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting pynndescent>=0.5.13 (from scanpy>=1.9.2->tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Using cached pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting session-info2 (from scanpy>=1.9.2->tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Downloading session_info2-0.2.2-py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Collecting statsmodels>=0.14.5 (from scanpy>=1.9.2->tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Downloading statsmodels-0.14.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.5 kB)\r\n",
      "Collecting umap-learn>=0.5.6 (from scanpy>=1.9.2->tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Downloading umap_learn-0.5.9.post2-py3-none-any.whl.metadata (25 kB)\r\n",
      "Collecting decorator (from ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting ipython-pygments-lexers (from ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "Collecting jedi>=0.16 (from ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting matplotlib-inline (from ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Using cached matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting pexpect>4.3 (from ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Using cached pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting prompt_toolkit<3.1.0,>=3.0.41 (from ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading prompt_toolkit-3.0.52-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Collecting pygments>=2.4.0 (from ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting stack_data (from ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Using cached stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting traitlets>=5.13.0 (from ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Using cached traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting comm>=0.1.3 (from ipywidgets->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2021.06.1->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting botocore<1.40.19,>=1.40.15 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2021.06.1->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading botocore-1.40.18-py3-none-any.whl.metadata (5.7 kB)\r\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2021.06.1->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\r\n",
      "Collecting multidict<7.0.0,>=6.0.0 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2021.06.1->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading multidict-6.6.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.3 kB)\r\n",
      "Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2021.06.1->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading wrapt-1.17.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\r\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2021.06.1->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2021.06.1->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2021.06.1->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (18 kB)\r\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2021.06.1->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading propcache-0.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\r\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2021.06.1->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading yarl-1.20.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (73 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m73.9/73.9 kB\u001B[0m \u001B[31m9.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting anyio (from httpx>=0.22.0->biothings-client>=0.2.6->mygene<4.0.0,>=3.2.2->PyTDC)\r\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Collecting httpcore==1.* (from httpx>=0.22.0->biothings-client>=0.2.6->mygene<4.0.0,>=3.2.2->PyTDC)\r\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\r\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.22.0->biothings-client>=0.2.6->mygene<4.0.0,>=3.2.2->PyTDC)\r\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading parso-0.8.5-py2.py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Collecting llvmlite<0.46,>=0.45.0dev0 (from numba>=0.57.1->scanpy>=1.9.2->tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Downloading llvmlite-0.45.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.8 kB)\r\n",
      "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Collecting wcwidth (from prompt_toolkit<3.1.0,>=3.0.41->ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Using cached wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\r\n",
      "INFO: pip is looking at multiple versions of umap-learn to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting umap-learn>=0.5.6 (from scanpy>=1.9.2->tiledbsoma<2.0.0,>=1.7.2->PyTDC)\r\n",
      "  Downloading umap_learn-0.5.8-py3-none-any.whl.metadata (23 kB)\r\n",
      "  Using cached umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\r\n",
      "Collecting donfig>=0.8 (from zarr!=3.0.*,>=2.18.7->anndata->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Collecting numcodecs>=0.14 (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading numcodecs-0.16.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.3 kB)\r\n",
      "Collecting executing>=1.2.0 (from stack_data->ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\r\n",
      "Collecting asttokens>=2.1.0 (from stack_data->ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\r\n",
      "Collecting pure-eval (from stack_data->ipython->gget<1.0.0,>=0.28.4->PyTDC)\r\n",
      "  Using cached pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Collecting crc32c>=2.7 (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata->cellxgene-census<2.0.0,>=1.10.2->PyTDC)\r\n",
      "  Downloading crc32c-2.7.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.3 kB)\r\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.22.0->biothings-client>=0.2.6->mygene<4.0.0,>=3.2.2->PyTDC)\r\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Downloading biopython-1.85-cp312-cp312-macosx_11_0_arm64.whl (2.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/2.8 MB\u001B[0m \u001B[31m20.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading cellxgene_census-1.17.0-py3-none-any.whl (55 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.6/55.6 kB\u001B[0m \u001B[31m5.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading dataclasses-0.6-py3-none-any.whl (14 kB)\r\n",
      "Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\r\n",
      "Downloading gget-0.29.3-py3-none-any.whl (43.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.1/43.1 MB\u001B[0m \u001B[31m21.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading huggingface_hub-0.35.0-py3-none-any.whl (563 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m563.4/563.4 kB\u001B[0m \u001B[31m17.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\r\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m250.9/250.9 kB\u001B[0m \u001B[31m12.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pandas-2.3.2-cp312-cp312-macosx_11_0_arm64.whl (10.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.7/10.7 MB\u001B[0m \u001B[31m21.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pydantic-2.11.9-py3-none-any.whl (444 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m444.9/444.9 kB\u001B[0m \u001B[31m16.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pydantic_core-2.33.2-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m19.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading rdkit-2023.9.6-cp312-cp312-macosx_11_0_arm64.whl (27.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m27.6/27.6 MB\u001B[0m \u001B[31m21.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached seaborn-0.13.2-py3-none-any.whl (294 kB)\r\n",
      "Downloading tiledbsoma-1.17.1-cp312-cp312-macosx_13_0_arm64.whl (27.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m27.0/27.0 MB\u001B[0m \u001B[31m21.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading somacore-1.0.28-py3-none-any.whl (38 kB)\r\n",
      "Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m256.2/256.2 kB\u001B[0m \u001B[31m16.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading anndata-0.12.2-py3-none-any.whl (169 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m169.9/169.9 kB\u001B[0m \u001B[31m13.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\r\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\r\n",
      "Downloading beautifulsoup4-4.13.5-py3-none-any.whl (105 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m105.1/105.1 kB\u001B[0m \u001B[31m12.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading biothings_client-0.4.1-py3-none-any.whl (46 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.7/46.7 kB\u001B[0m \u001B[31m4.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m199.3/199.3 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.6/2.6 MB\u001B[0m \u001B[31m21.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading matplotlib-3.10.6-cp312-cp312-macosx_11_0_arm64.whl (8.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.1/8.1 MB\u001B[0m \u001B[31m20.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading mysql_connector_python-9.4.0-cp312-cp312-macosx_14_0_arm64.whl (17.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m17.5/17.5 MB\u001B[0m \u001B[31m21.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m66.5/66.5 kB\u001B[0m \u001B[31m7.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pillow-11.3.0-cp312-cp312-macosx_11_0_arm64.whl (4.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.7/4.7 MB\u001B[0m \u001B[31m21.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\r\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m509.2/509.2 kB\u001B[0m \u001B[31m16.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m173.3/173.3 kB\u001B[0m \u001B[31m13.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading s3fs-2025.9.0-py3-none-any.whl (30 kB)\r\n",
      "Downloading scanpy-1.11.4-py3-none-any.whl (2.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m20.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.6/44.6 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\r\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m347.8/347.8 kB\u001B[0m \u001B[31m16.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\r\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\r\n",
      "Downloading ipython-9.5.0-py3-none-any.whl (612 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m612.4/612.4 kB\u001B[0m \u001B[31m18.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m139.8/139.8 kB\u001B[0m \u001B[31m9.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading lxml-6.0.2-cp312-cp312-macosx_10_13_universal2.whl (8.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.7/8.7 MB\u001B[0m \u001B[31m21.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m69.7/69.7 kB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pyarrow-21.0.0-cp312-cp312-macosx_12_0_arm64.whl (31.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m31.2/31.2 MB\u001B[0m \u001B[31m21.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading aiobotocore-2.24.2-py3-none-any.whl (85 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m85.4/85.4 kB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading aiohttp-3.12.15-cp312-cp312-macosx_11_0_arm64.whl (469 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m469.8/469.8 kB\u001B[0m \u001B[31m17.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading array_api_compat-1.12.0-py3-none-any.whl (58 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.2/58.2 kB\u001B[0m \u001B[31m7.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading comm-0.2.3-py3-none-any.whl (7.3 kB)\r\n",
      "Downloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl (273 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m274.0/274.0 kB\u001B[0m \u001B[31m13.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hUsing cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\r\n",
      "Downloading fonttools-4.60.0-cp312-cp312-macosx_10_13_universal2.whl (2.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/2.8 MB\u001B[0m \u001B[31m20.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading h5py-3.14.0-cp312-cp312-macosx_11_0_arm64.whl (2.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/2.8 MB\u001B[0m \u001B[31m20.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m73.5/73.5 kB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.8/78.8 kB\u001B[0m \u001B[31m6.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m19.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m216.6/216.6 kB\u001B[0m \u001B[31m13.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading kiwisolver-1.4.9-cp312-cp312-macosx_11_0_arm64.whl (64 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m65.0/65.0 kB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading legacy_api_wrap-1.4.1-py3-none-any.whl (10.0 kB)\r\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m19.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading numba-0.62.0-cp312-cp312-macosx_11_0_arm64.whl (2.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.7/2.7 MB\u001B[0m \u001B[31m20.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m232.9/232.9 kB\u001B[0m \u001B[31m11.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hUsing cached pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\r\n",
      "Downloading prompt_toolkit-3.0.52-py3-none-any.whl (391 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m391.4/391.4 kB\u001B[0m \u001B[31m13.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m20.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached pynndescent-0.5.13-py3-none-any.whl (56 kB)\r\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m113.9/113.9 kB\u001B[0m \u001B[31m10.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\r\n",
      "Downloading statsmodels-0.14.5-cp312-cp312-macosx_11_0_arm64.whl (9.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.7/9.7 MB\u001B[0m \u001B[31m21.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached traitlets-5.14.3-py3-none-any.whl (85 kB)\r\n",
      "Using cached umap_learn-0.5.7-py3-none-any.whl (88 kB)\r\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m19.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading zarr-3.1.3-py3-none-any.whl (276 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m276.4/276.4 kB\u001B[0m \u001B[31m13.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\r\n",
      "Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)\r\n",
      "Using cached matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\r\n",
      "Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\r\n",
      "Downloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\r\n",
      "Downloading session_info2-0.2.2-py3-none-any.whl (16 kB)\r\n",
      "Downloading shapely-2.1.1-cp312-cp312-macosx_11_0_arm64.whl (1.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m19.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached stack_data-0.6.3-py3-none-any.whl (24 kB)\r\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\r\n",
      "Downloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\r\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\r\n",
      "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\r\n",
      "Downloading botocore-1.40.18-py3-none-any.whl (14.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.0/14.0 MB\u001B[0m \u001B[31m21.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\r\n",
      "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\r\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-macosx_11_0_arm64.whl (46 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.7/46.7 kB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\r\n",
      "Downloading llvmlite-0.45.0-cp312-cp312-macosx_11_0_arm64.whl (37.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m37.3/37.3 MB\u001B[0m \u001B[31m21.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading multidict-6.6.4-cp312-cp312-macosx_11_0_arm64.whl (43 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.6/43.6 kB\u001B[0m \u001B[31m4.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading numcodecs-0.16.3-cp312-cp312-macosx_11_0_arm64.whl (1.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m19.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading parso-0.8.5-py2.py3-none-any.whl (106 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m106.7/106.7 kB\u001B[0m \u001B[31m8.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading propcache-0.3.2-cp312-cp312-macosx_11_0_arm64.whl (43 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.1/43.1 kB\u001B[0m \u001B[31m4.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hUsing cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\r\n",
      "Downloading wrapt-1.17.3-cp312-cp312-macosx_11_0_arm64.whl (39 kB)\r\n",
      "Downloading yarl-1.20.1-cp312-cp312-macosx_11_0_arm64.whl (89 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m89.7/89.7 kB\u001B[0m \u001B[31m8.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading anyio-4.10.0-py3-none-any.whl (107 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m107.2/107.2 kB\u001B[0m \u001B[31m8.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hUsing cached pure_eval-0.2.3-py3-none-any.whl (11 kB)\r\n",
      "Using cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\r\n",
      "Downloading crc32c-2.7.1-cp312-cp312-macosx_11_0_arm64.whl (35 kB)\r\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\r\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\r\n",
      "Building wheels for collected packages: PyTDC, scikit-learn\r\n",
      "  Building wheel for PyTDC (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for PyTDC: filename=PyTDC-1.0.0-py3-none-any.whl size=177946 sha256=1d1d779fec46c4f6d1db0762259f7c4e9a8ecdde80ab1056ad8e6faf80a51124\r\n",
      "  Stored in directory: /Users/afnan_sultan/Library/Caches/pip/wheels/c8/b2/df/def482293314b03bd5c2d72c94088b79e70437b4a731099f83\r\n",
      "  Building wheel for scikit-learn (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for scikit-learn: filename=scikit_learn-1.2.2-cp312-cp312-macosx_11_0_arm64.whl size=8328786 sha256=17f8a4ff84300676dacc3aeab32be1595be4f3c8093e3063e3cff33c0e72cffc\r\n",
      "  Stored in directory: /Users/afnan_sultan/Library/Caches/pip/wheels/24/f8/77/ae90c181b806f450a6fec8c8f794594e7c92fa79d7ca27e656\r\n",
      "Successfully built PyTDC scikit-learn\r\n",
      "Installing collected packages: wcwidth, pytz, pure-eval, ptyprocess, fuzzywuzzy, dataclasses, yapf, wrapt, widgetsnbextension, tzdata, typing_extensions, traitlets, soupsieve, sniffio, six, shapely, session-info2, pyyaml, pyparsing, pygments, pyarrow-hotfix, pyarrow, propcache, prompt_toolkit, Pillow, pexpect, patsy, parso, packaging, networkx, natsort, mysql-connector-python, multidict, more-itertools, lxml, llvmlite, legacy-api-wrap, kiwisolver, jupyterlab_widgets, jmespath, hf-xet, h5py, h11, fsspec, frozenlist, fonttools, filelock, executing, et-xmlfile, decorator, cycler, crc32c, contourpy, comm, biopython, attrs, asttokens, array-api-compat, annotated-types, aioitertools, aiohappyeyeballs, yarl, typing-inspection, stack_data, scikit-learn, rdkit, python-dateutil, pydantic-core, openpyxl, numcodecs, numba, matplotlib-inline, jedi, ipython-pygments-lexers, huggingface_hub, httpcore, donfig, beautifulsoup4, anyio, aiosignal, pynndescent, pydantic, pandas, matplotlib, ipython, httpx, botocore, aiohttp, zarr, umap-learn, statsmodels, seaborn, ipywidgets, biothings-client, aiobotocore, s3fs, mygene, gget, anndata, somacore, scanpy, tiledbsoma, cellxgene-census, PyTDC\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 23.2\r\n",
      "    Uninstalling packaging-23.2:\r\n",
      "      Successfully uninstalled packaging-23.2\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.3.2\r\n",
      "    Uninstalling scikit-learn-1.3.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.3.2\r\n",
      "Successfully installed Pillow-11.3.0 PyTDC-1.0.0 aiobotocore-2.24.2 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aioitertools-0.12.0 aiosignal-1.4.0 anndata-0.12.2 annotated-types-0.7.0 anyio-4.10.0 array-api-compat-1.12.0 asttokens-3.0.0 attrs-25.3.0 beautifulsoup4-4.13.5 biopython-1.85 biothings-client-0.4.1 botocore-1.40.18 cellxgene-census-1.17.0 comm-0.2.3 contourpy-1.3.3 crc32c-2.7.1 cycler-0.12.1 dataclasses-0.6 decorator-5.2.1 donfig-0.8.1.post1 et-xmlfile-2.0.0 executing-2.2.1 filelock-3.19.1 fonttools-4.60.0 frozenlist-1.7.0 fsspec-2025.9.0 fuzzywuzzy-0.18.0 gget-0.29.3 h11-0.16.0 h5py-3.14.0 hf-xet-1.1.10 httpcore-1.0.9 httpx-0.28.1 huggingface_hub-0.35.0 ipython-9.5.0 ipython-pygments-lexers-1.1.1 ipywidgets-8.1.7 jedi-0.19.2 jmespath-1.0.1 jupyterlab_widgets-3.0.15 kiwisolver-1.4.9 legacy-api-wrap-1.4.1 llvmlite-0.45.0 lxml-6.0.2 matplotlib-3.10.6 matplotlib-inline-0.1.7 more-itertools-10.8.0 multidict-6.6.4 mygene-3.2.2 mysql-connector-python-9.4.0 natsort-8.4.0 networkx-3.5 numba-0.62.0 numcodecs-0.16.3 openpyxl-3.1.5 packaging-25.0 pandas-2.3.2 parso-0.8.5 patsy-1.0.1 pexpect-4.9.0 prompt_toolkit-3.0.52 propcache-0.3.2 ptyprocess-0.7.0 pure-eval-0.2.3 pyarrow-21.0.0 pyarrow-hotfix-0.7 pydantic-2.11.9 pydantic-core-2.33.2 pygments-2.19.2 pynndescent-0.5.13 pyparsing-3.2.5 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.2 rdkit-2023.9.6 s3fs-2025.9.0 scanpy-1.11.4 scikit-learn-1.2.2 seaborn-0.13.2 session-info2-0.2.2 shapely-2.1.1 six-1.17.0 sniffio-1.3.1 somacore-1.0.28 soupsieve-2.8 stack_data-0.6.3 statsmodels-0.14.5 tiledbsoma-1.17.1 traitlets-5.14.3 typing-inspection-0.4.1 typing_extensions-4.15.0 tzdata-2025.2 umap-learn-0.5.7 wcwidth-0.2.13 widgetsnbextension-4.0.14 wrapt-1.17.3 yapf-0.43.0 yarl-1.20.1 zarr-3.1.3\r\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39msystem(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpip install PyTDC\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(torch\u001B[38;5;241m.\u001B[39m__version__)\n\u001B[1;32m      4\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39msystem(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpip install torch-geometric torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-\u001B[39m\u001B[38;5;132;01m{torch.__version__}\u001B[39;00m\u001B[38;5;124m.html\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The most important aspect: Well-curated data\n",
    "## Therapeutics Data Commons: An easily accessible source\n",
    "- lots of standard data sets on [tdcommons.ai](https://tdcommons.ai)\n",
    "- easy data splitting (random, scaffold, cold_*)\n",
    "\n",
    "## A solubility dataset: AqSolDB\n",
    "- made by [Sorkun, Khetan, Er (2019)](https://www.nature.com/articles/s41597-019-0151-1)\n",
    "- compound data set (merged 9 data sets)\n",
    "- handling of duplicates and multiple measurements:\n",
    "  - more than 2: select the one closest to the mean\n",
    "  - 2 measurements: select the one closest to ALOGPS prediction"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tdc.single_pred import ADME\n",
    "data = ADME(name = 'Solubility_AqSolDB')\n",
    "split = data.get_split(method='random')\n",
    "data.print_stats()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "split['train']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Label distribution\n",
    "\n",
    "It's important to see the range of our data, the size, and the distribution.\n",
    "\n",
    "This gives us an idea about where most of the data are clustered and whether our molecules are biased to a specific range.\n",
    "\n",
    "Below we see our data mostly between -9 ans 2.5 LogS, but we still see some few molecules that are scoring lower LogS values."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# concatenate train + test into one Series\n",
    "y_all = pd.concat([split['train']['Y'], split['test']['Y']]).dropna()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "\n",
    "# KDE for all data\n",
    "sns.kdeplot(y_all, ax=ax, fill=True, alpha=0.3, color=\"tab:blue\", label=\"All data\")\n",
    "\n",
    "# twin axis for boxplot\n",
    "ax2 = ax.twinx()\n",
    "pos = 0\n",
    "ax2.boxplot(y_all, vert=False, positions=[pos], widths=0.12, patch_artist=True,\n",
    "            boxprops=dict(facecolor=\"none\", edgecolor=\"tab:blue\"),\n",
    "            medianprops=dict(color=\"tab:blue\"))\n",
    "ax2.plot(np.mean(y_all), pos, marker='^', color='red', markersize=8, zorder=3)\n",
    "\n",
    "# clean up the twin axis\n",
    "ax2.set_axis_off()\n",
    "\n",
    "# labels and title\n",
    "ax.set_xlabel(\"LogS\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_title(f\"Y distribution (All data, n={len(y_all)})\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Featurization - The model doesn't see a molecule, it sees a *representation* of a molecule!\n",
    "- __rdkit__ is the main tool for working with molecules\n",
    "- `rdFingerprintGenerator` can  produce a multitude of fingerprints.\n",
    "- We use the Morgan fingerprint approach to represet our molecules as a bit vector `GetMorganFingerprintAsBitVect`\n",
    "\n",
    "## But... what exactly is this representation, and how it is generated?\n",
    "\n",
    "- It's a way to convert a molecule into a binary vectors of 0s and 1s\n",
    "- Each bit corresponds to an atom in an environment such as\n",
    "  - Atomic number and connectivity/valence cues.\n",
    "  - Hydrogen information\n",
    "  - Formal charge.\n",
    "  - Aromaticity flag.\n",
    "  - Ring membership\n",
    "  - Chirality (optional)\n",
    "- The environment cues form a integer of 32 bits, and this integer is the identity of this atom in this environment[$^1$].\n",
    "  - This id gets hashed to map to a single bit index in the bit vector.\n",
    "    - The equation to get the bit index is `ìd % nBits`\n",
    "- An activated bit (i.e., bit = 1), means that this atom in this environment is present in this molecule.\n",
    "- The environment is defined circularly by choosing a radius to decide how many connecting atoms to consider\n",
    "  - The radius is user defined\n",
    "  - When using raius = n, the algorithm automatically calculates radius = 0, 0+1, 0+1+2, ... , 0+1+...+n-1+n\n",
    "- The length of the vector is user defined\n",
    "  - Longer vector = more environments to store.\n",
    "    - But it also means that many bits will be zeros in most of the molecules because not all atom-environment pairs exist in all molecules (i.e., the vectors become sparse)\n",
    "\n",
    "The below animation walks you through the construction of this algorithm.\n",
    "\n",
    "Pay attention to bit at index 1 in the two molecules, and see when (and how many times) it gets activated.\n",
    "- **Is it always the same atom-environment pair that activates it?**\n",
    "\n",
    "Pay attention to index 1 in the Caffeine example\n",
    "- **Does it get activated each time by the same atom-environment pair?**\n",
    "\n",
    "---\n",
    "\n",
    "[$^1$]: check this atom-enviroment coding for at `O` in an `O=C` environment.\n",
    "- Number of non-hydrogen immediate neighbors = 3\n",
    "- Valency minus the number of connected hydrogens = 4\n",
    "- Atomic number = 6\n",
    "- Atomic mass = 12\n",
    "- Atomic charge = 0\n",
    "- Number of attached hydrogens = 0\n",
    "- Atom is a part of at least one ring = 0\n",
    "\n",
    "`atom-environment pair ID = hash((3, 4, 6, 12, 0, 0, 0))`"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.rdMolDescriptors import GetMorganFingerprintAsBitVect\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator, AdditionalOutput\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image as PilImage\n",
    "from IPython.display import HTML\n",
    "\n",
    "# --- Example molecules ---\n",
    "examples = [\n",
    "    (\"Example #1: Phenol\", \"c1ccccc1O\"),\n",
    "    (\"Example #2: Caffeine\", \"Cn1cnc2c1c(=O)n(c(=O)n2C)C\")\n",
    "]\n",
    "\n",
    "# --- Parameters ---\n",
    "radius = 2\n",
    "nBits = 32\n",
    "mfpgen_folded   = GetMorganGenerator(radius=radius, fpSize=nBits)  # folded\n",
    "mfpgen_unfolded = GetMorganGenerator(radius=radius)                # unfolded\n",
    "\n",
    "# --- Collect steps for all molecules ---\n",
    "all_steps = []\n",
    "for ex_id, (name, smi) in enumerate(examples):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    AllChem.Compute2DCoords(mol)\n",
    "\n",
    "    # folded bitInfo\n",
    "    bitInfo = {}\n",
    "    _ = GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=nBits, bitInfo=bitInfo)\n",
    "\n",
    "    # unfolded raw IDs\n",
    "    info = AdditionalOutput()\n",
    "    info.CollectBitInfoMap()\n",
    "    _ = mfpgen_unfolded.GetFingerprint(mol, additionalOutput=info)\n",
    "    bitInfoFull = info.GetBitInfoMap()  # raw env_id → [(atom_idx, rad), ...]\n",
    "\n",
    "    for bit, infos in bitInfo.items():  # folded bits\n",
    "        for atom_idx, rad in infos:\n",
    "            env = Chem.FindAtomEnvironmentOfRadiusN(mol, rad, atom_idx)\n",
    "            atoms = {atom_idx}\n",
    "            for b in env:\n",
    "                bond = mol.GetBondWithIdx(b)\n",
    "                atoms.add(bond.GetBeginAtomIdx())\n",
    "                atoms.add(bond.GetEndAtomIdx())\n",
    "\n",
    "            # find raw env_id (32-bit)\n",
    "            env_id = None\n",
    "            for rid, tuples in bitInfoFull.items():\n",
    "                for a, r in tuples:\n",
    "                    if a == atom_idx and r == rad:\n",
    "                        env_id = rid   # raw 32-bit env ID\n",
    "                        break\n",
    "                if env_id is not None:\n",
    "                    break\n",
    "\n",
    "            all_steps.append((ex_id, name, mol, rad, atom_idx, atoms, env, bit, env_id))\n",
    "\n",
    "# sort: example first, then radius, then atom index\n",
    "all_steps.sort(key=lambda x: (x[0], x[3], x[4]))\n",
    "\n",
    "# ranges for reset per example\n",
    "ex_ranges = {}\n",
    "i = 0\n",
    "while i < len(all_steps):\n",
    "    ex_id = all_steps[i][0]\n",
    "    j = i\n",
    "    while j < len(all_steps) and all_steps[j][0] == ex_id:\n",
    "        j += 1\n",
    "    ex_ranges[ex_id] = (i, j)\n",
    "    i = j\n",
    "\n",
    "# --- Helper: draw molecule gray + highlight red ---\n",
    "def mol_to_image_gray_base_with_highlight(mol, atoms=None, bonds=None, center_atom=None,\n",
    "                                          size=(500, 500),\n",
    "                                          gray_rgb=(160, 160, 160), black_thresh=40):\n",
    "    m = Chem.Mol(mol)\n",
    "    drawer = rdMolDraw2D.MolDraw2DCairo(size[0], size[1])\n",
    "    opts = drawer.drawOptions()\n",
    "    opts.padding = 0.02\n",
    "    opts.bondLineWidth = 2\n",
    "    if hasattr(opts, \"useBWAtomPalette\"):\n",
    "        opts.useBWAtomPalette()\n",
    "\n",
    "    atom_colors = {}\n",
    "    if atoms:\n",
    "        for a in atoms:\n",
    "            if a == center_atom:\n",
    "                atom_colors[a] = (1.0, 1.0, 0.0)   # yellow center atom\n",
    "            else:\n",
    "                atom_colors[a] = (1.0, 0.0, 0.0)   # red neighbors\n",
    "    bond_colors = {b: (1.0, 0.0, 0.0) for b in (bonds or [])}\n",
    "\n",
    "    rdMolDraw2D.PrepareAndDrawMolecule(\n",
    "        drawer, m,\n",
    "        highlightAtoms=list(atoms) if atoms else [],\n",
    "        highlightBonds=list(bonds) if bonds else [],\n",
    "        highlightAtomColors=atom_colors,\n",
    "        highlightBondColors=bond_colors,\n",
    "    )\n",
    "    drawer.FinishDrawing()\n",
    "    img = PilImage.open(io.BytesIO(drawer.GetDrawingText())).convert(\"RGBA\")\n",
    "\n",
    "    arr = np.asarray(img).copy()\n",
    "    rgb, alpha = arr[..., :3], arr[..., 3]\n",
    "    near_black = (rgb[..., 0] < black_thresh) & (rgb[..., 1] < black_thresh) & \\\n",
    "                 (rgb[..., 2] < black_thresh) & (alpha > 0)\n",
    "    arr[..., :3][near_black] = gray_rgb\n",
    "    return PilImage.fromarray(arr, mode=\"RGBA\")\n",
    "\n",
    "# --- Fingerprint panel ---\n",
    "def draw_fingerprint(ax, bit_array, highlight=None):\n",
    "    ax.clear()\n",
    "    ax.set_xlim(0, nBits)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks(range(nBits))\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(\"Fingerprint Bits\", fontsize=14, pad=8)\n",
    "    for i in range(nBits):\n",
    "        color = \"white\" if bit_array[i] == 0 else \"black\"\n",
    "        rect = Rectangle((i, 0.4), 0.9, 0.2, facecolor=color,\n",
    "                         edgecolor=\"black\", linewidth=0.8)\n",
    "        ax.add_patch(rect)\n",
    "    if highlight is not None:\n",
    "        rect = Rectangle((highlight, 0.4), 0.9, 0.2, facecolor=\"red\",\n",
    "                         edgecolor=\"black\", linewidth=1.2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "# --- Animation setup ---\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "gs = fig.add_gridspec(2, 1, height_ratios=[2.5, 1])\n",
    "ax_mol = fig.add_subplot(gs[0])\n",
    "ax_fp  = fig.add_subplot(gs[1])\n",
    "\n",
    "bit_array = np.zeros(nBits, dtype=int)\n",
    "\n",
    "def update(frame):\n",
    "    ex_id, ex_name, mol, rad, atom_idx, atoms, bonds, bit, env_id = all_steps[frame]\n",
    "\n",
    "    # reset bits for this example only\n",
    "    start, _ = ex_ranges[ex_id]\n",
    "    bit_array[:] = 0\n",
    "    for _, _, _, _, _, _, _, b, _ in all_steps[start:frame+1]:\n",
    "        bit_array[b] = 1\n",
    "\n",
    "    # clear mol panel\n",
    "    ax_mol.clear()\n",
    "    img = mol_to_image_gray_base_with_highlight(mol, atoms=atoms,\n",
    "                                                bonds=bonds, center_atom=atom_idx,\n",
    "                                                size=(500, 500))\n",
    "    ax_mol.imshow(img)\n",
    "    ax_mol.axis(\"off\")\n",
    "    ax_mol.set_title(f\"{ex_name} | Atom {atom_idx}, Radius {rad}\", fontsize=16, pad=15)\n",
    "\n",
    "    # small table to right of molecule\n",
    "    ax_table = ax_mol.inset_axes([-0.8, -0.6, 0.9, 1.2])  # X, y, width, height\n",
    "    ax_table.axis(\"off\")\n",
    "    table_data = [[atom_idx, rad, env_id, env_id % nBits]]\n",
    "    table = ax_table.table(cellText=table_data,\n",
    "                           colLabels=[\"Atom\", \"Radius\", \"id\", \"id % nBits\"],\n",
    "                           loc=\"center\", cellLoc=\"center\")\n",
    "    table.scale(1.0, 1.2)\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "\n",
    "    draw_fingerprint(ax_fp, bit_array, highlight=bit)\n",
    "\n",
    "# --- Run animation ---\n",
    "ani = FuncAnimation(fig, update, frames=len(all_steps), interval=1500, repeat=False)\n",
    "HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# Quiet rdkit warnings\n",
    "RDLogger.logger().setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "# --- setup Morgan generator ---\n",
    "nBits = 1024\n",
    "radius = 2\n",
    "mfpgen = rdFingerprintGenerator.GetMorganGenerator(radius=radius, fpSize=nBits)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data splitting\n",
    "\n",
    "We need to split our data into train and test sets so that we have some molecules to test our model on once finished training.\n",
    "\n",
    "Today we use a vanilla splitting approach, which randomly assignes molecules to train and test sets with a ratio of 80:20.\n",
    "\n",
    "We use the 80% to train the model, and the 20% to test it."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "smiles2fp = lambda smiles: mfpgen.GetFingerprintAsNumPy(Chem.MolFromSmiles(smiles))\n",
    "X_train = np.stack(list(map(smiles2fp, tqdm.tqdm(split['train']['Drug']))))\n",
    "y_train = split['train']['Y'].values\n",
    "X_test = np.stack(list(map(smiles2fp, tqdm.tqdm(split['test']['Drug']))))\n",
    "y_test = split['test']['Y'].values"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's visualize the label distribution of both train and test sets.\n",
    "\n",
    "The two distributions span similar range and shape. This tells us that our model will not be failing due to a distributional shift!\n",
    "\n",
    "If it fails, it will be because of something else! 🙃"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "sns.kdeplot(y_train, fill=True, alpha=0.4, color=\"tab:blue\", label=f\"Train ({len(y_train)})\")\n",
    "sns.kdeplot(y_test,  fill=True, alpha=0.4, color=\"tab:orange\", label=f\"Test ({len(y_test)})\")\n",
    "sns.rugplot(y_train)\n",
    "sns.rugplot(y_test)\n",
    "plt.xlabel('LogS')\n",
    "plt.legend()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Looking deeper into our representation\n",
    "\n",
    "One thing we can do as an explorative analysis, is to briefly see what the model sees.\n",
    "\n",
    "Currently, the `X_train` variable is just a vector of 0s and 1s.\n",
    "\n",
    "We retrieve the meta data of each bit (i.e., the environment) and we use the molecular graph of the molecules to construct the substructure encoded in each bit."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- build list of molecules from SMILES ---\n",
    "smiles_list = split['train']['Drug'].tolist()\n",
    "mols = [Chem.MolFromSmiles(smi) for smi in smiles_list]\n",
    "\n",
    "# --- collect bitInfo for each mol ---\n",
    "bitinfos = []\n",
    "for mol in mols:\n",
    "    info = {}\n",
    "    # radius must match your fingerprint generator (e.g. 2 for Morgan radius=2)\n",
    "    _ = AllChem.GetMorganFingerprintAsBitVect(\n",
    "        mol,\n",
    "        radius=2,\n",
    "        nBits=X_train.shape[1],\n",
    "        bitInfo=info\n",
    "    )\n",
    "    bitinfos.append(info)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1- How frequent are the bits?\n",
    "\n",
    "The below figure show the percentage of molecules that activated a given bit.\n",
    "\n",
    "There are a few bits that were activated in over 50% of the molecules, but the majority of the bits were active in less than 10% only."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Count number of molecules where each bit is active\n",
    "bit_counts = X_train.sum(axis=0)   # shape: (n_bits,)\n",
    "n_mols = X_train.shape[0]\n",
    "\n",
    "# Convert to percentages\n",
    "bit_percents = (bit_counts / n_mols) * 100\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(np.arange(len(bit_percents)), bit_percents, color=\"steelblue\")\n",
    "plt.xlabel(\"Fingerprint bit index\")\n",
    "plt.ylabel(\"Percentage of molecules activating this bit (%)\")\n",
    "plt.title(\"Bit activity percentages in training set\")\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2- What about collisions?\n",
    "\n",
    "Collisions happen when the encoding of an atom and its environment ends up in the same bit as another atom and environment.\n",
    "\n",
    "--\n",
    "\n",
    "Two atom-environment pairs can map to the same bit **artifitially** as the way to assing an atom-environment identifier (id) to a bit is by getting the mod of `id % nBits` (see the animation).\n",
    "\n",
    "Thus, two ids when divided by the vector length, can yeild the same mod.\n",
    "\n",
    "For example, assume we have these two atom-environment pairs identifiers\n",
    "<br>id1 = 123456\n",
    "<br>id2 = 124480\n",
    "\n",
    "id2 % 1024 = 960\n",
    "<br>id2 % 1024 = 960\n",
    "\n",
    "Both pair activate bit index 960.\n",
    "\n",
    "--\n",
    "\n",
    "But two atom-environment pair can lead to the same bit because they got the same identifier. And this happens when the two pairs are **chemically similar** that their environment infomation led to the same id.\n",
    "\n",
    "--\n",
    "\n",
    "The left plot below looks at each molecule and checks how many atom-environment pairs map to the same bit, and whether it is an artificial collision or chemical collision.\n",
    "\n",
    "The right plot looks at the bits and see how many molecules showed this mapping for this bit, as well as the type of mapping (i.e., artifitial or chemicaly similar)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from collections import defaultdict, Counter\n",
    "import hashlib\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "def get_morgan_env_ids(mol, radius=2, nBits=1024):\n",
    "    \"\"\"\n",
    "    Compute raw 32-bit IDs and folded IDs for all atom environments.\n",
    "    Returns a list of (raw_id, folded_id, atom_idx, radius).\n",
    "    \"\"\"\n",
    "    env_ids = []\n",
    "    invariants = rdMolDescriptors.GetConnectivityInvariants(mol)\n",
    "\n",
    "    for atom_idx in range(mol.GetNumAtoms()):\n",
    "        for rad in range(radius + 1):\n",
    "            env = Chem.FindAtomEnvironmentOfRadiusN(mol, rad, atom_idx)\n",
    "            atoms = {atom_idx}\n",
    "            for b in env:\n",
    "                bond = mol.GetBondWithIdx(b)\n",
    "                atoms.add(bond.GetBeginAtomIdx())\n",
    "                atoms.add(bond.GetEndAtomIdx())\n",
    "\n",
    "            # encode environment string\n",
    "            env_string = \";\".join(f\"{a}:{invariants[a]}\" for a in sorted(atoms)) \\\n",
    "                       + \"|\" + \",\".join(str(b) for b in sorted(env))\n",
    "\n",
    "            # SHA1 → 32-bit ID\n",
    "            raw_id = int(hashlib.sha1(env_string.encode(\"utf-8\")).hexdigest(), 16) & 0xFFFFFFFF\n",
    "            folded_id = raw_id % nBits\n",
    "\n",
    "            env_ids.append((raw_id, folded_id, atom_idx, rad))\n",
    "\n",
    "    return env_ids\n",
    "\n",
    "# --- Step 1: per-molecule collision classification ---\n",
    "chem_counts, art_counts = [], []\n",
    "chem_bit_counter, art_bit_counter = Counter(), Counter()\n",
    "\n",
    "for smi in smiles_list:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    env_ids = get_morgan_env_ids(mol, radius=2)  # from earlier helper\n",
    "    folded_map = defaultdict(list)\n",
    "    for raw_id, folded_id, atom_idx, rad in env_ids:\n",
    "        folded_map[folded_id].append(raw_id)\n",
    "\n",
    "    # classify per-molecule collisions\n",
    "    c, a = 0, 0\n",
    "    for bit, raws in folded_map.items():\n",
    "        if len(raws) > 1:\n",
    "            if len(set(raws)) == 1:\n",
    "                c += 1\n",
    "                chem_bit_counter[bit] += 1\n",
    "            else:\n",
    "                a += 1\n",
    "                art_bit_counter[bit] += 1\n",
    "    chem_counts.append(c)\n",
    "    art_counts.append(a)\n",
    "\n",
    "nMols = len(smiles_list)\n",
    "\n",
    "print(f\"Avg chemical duplicates per molecule: {np.mean(chem_counts):.2f}\")\n",
    "print(f\"Avg artificial collisions per molecule: {np.mean(art_counts):.2f}\")\n",
    "\n",
    "# --- Step 2: per-bit percentages ---\n",
    "chem_perc = {b: c/nMols*100 for b,c in chem_bit_counter.items()}\n",
    "art_perc  = {b: c/nMols*100 for b,c in art_bit_counter.items()}\n",
    "all_bits = set(chem_perc) | set(art_perc)\n",
    "totals = {b: chem_perc.get(b,0)+art_perc.get(b,0) for b in all_bits}\n",
    "\n",
    "# Top-k bits\n",
    "k = 10\n",
    "top_bits = sorted(totals, key=totals.get, reverse=True)[:k]\n",
    "chem_vals = [chem_perc.get(b,0) for b in top_bits]\n",
    "art_vals  = [art_perc.get(b,0) for b in top_bits]\n",
    "\n",
    "# --- Step 3: plots ---\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14,5))\n",
    "\n",
    "# (A) Histogram per molecule (collision type distribution)\n",
    "all_counts = np.array(chem_counts + art_counts)\n",
    "bins = np.arange(all_counts.min(), all_counts.max() + 2) - 0.5  # integer bins\n",
    "\n",
    "axs[0].hist(chem_counts, bins=bins,\n",
    "            weights=np.ones_like(chem_counts)*100.0/nMols,\n",
    "            color=\"tab:blue\", alpha=0.7, edgecolor=\"black\", label=\"Chemical duplicates\")\n",
    "axs[0].hist(art_counts, bins=bins,\n",
    "            weights=np.ones_like(art_counts)*100.0/nMols,\n",
    "            color=\"tab:orange\", alpha=0.7, edgecolor=\"black\", label=\"Artificial collisions\")\n",
    "\n",
    "axs[0].set_xlabel(\"Number of colliding bits per molecule\")\n",
    "axs[0].set_ylabel(\"% of molecules\")\n",
    "axs[0].yaxis.set_major_formatter(PercentFormatter())\n",
    "axs[0].set_title(\"Collision types per molecule\")\n",
    "axs[0].legend()\n",
    "\n",
    "# (B) Top-k bits with stacked bars\n",
    "x = np.arange(k)\n",
    "axs[1].bar(x, chem_vals, color=\"tab:blue\", label=\"Chemical duplicates\")\n",
    "axs[1].bar(x, art_vals, bottom=chem_vals, color=\"tab:orange\", label=\"Artificial collisions\")\n",
    "axs[1].set_xticks(x)\n",
    "axs[1].set_xticklabels(top_bits, rotation=90)\n",
    "axs[1].set_ylabel(\"% of molecules with collision\")\n",
    "axs[1].set_xlabel(\"Bit index\")\n",
    "axs[1].set_title(f\"Top {k} colliding bits (by type)\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3- How informative are the bits?\n",
    "\n",
    "Now, each bit is activated in a group of molecules.\n",
    "\n",
    "One can have a quick idea about the functionality of this bit by checking the solubility distribution of the moelcules activated by it.\n",
    "\n",
    "--\n",
    "\n",
    "If these molecules have a very close values (i.e., small variance), then this bit is likely informative to predict this solubility range.\n",
    "\n",
    "--\n",
    "\n",
    "In the below image, we see the most frquent bits in our dataset shown as the bars.\n",
    "\n",
    "Then a second plot is overlayed that shows the mean and standard deviation of the molecules activated by this bit.\n",
    "\n",
    "We can already see that the ranges are very wide per bit, and that most groups have similar ranges.\n",
    "\n",
    "--\n",
    "\n",
    "An exception is bit 366 where the values show to be noticeably lower that the other ones.\n",
    "\n",
    "However, the overall trend tells us that there seem to not be a single bit that gives us a lot of information immediately."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import numpy as np\n",
    "\n",
    "# Count how many molecules activate each bit\n",
    "bit_counts = X_train.sum(axis=0)\n",
    "n_mols = X_train.shape[0]\n",
    "\n",
    "# Top-k bits (same ranking since percentage = count / n_mols)\n",
    "k = 50\n",
    "top_idx = np.argsort(-bit_counts)[:k]\n",
    "top_counts = bit_counts[top_idx]\n",
    "\n",
    "# Sort descending for nice order\n",
    "sorted_idx = np.argsort(-top_counts)\n",
    "top_idx = top_idx[sorted_idx]\n",
    "top_percents = (top_counts[sorted_idx] / n_mols) * 100\n",
    "\n",
    "# ---- compute mean ± sigma of y for the \"bit=1\" group, in the same order ----\n",
    "means_on = []\n",
    "stds_on = []\n",
    "for b in top_idx:\n",
    "    mask = X_train[:, b].astype(bool)\n",
    "    y_on = y_train[mask]\n",
    "    if y_on.size == 0:\n",
    "        means_on.append(np.nan)\n",
    "        stds_on.append(np.nan)\n",
    "    else:\n",
    "        means_on.append(np.nanmean(y_on))\n",
    "        # use ddof=1 for sample std if n>=2, else 0\n",
    "        stds_on.append(np.nanstd(y_on, ddof=1) if y_on.size > 1 else 0.0)\n",
    "\n",
    "means_on = np.array(means_on, dtype=float)\n",
    "stds_on  = np.array(stds_on, dtype=float)\n",
    "\n",
    "x = np.arange(k)\n",
    "\n",
    "# ---- plot: bars (percent) on left axis + mean±sigma line on right axis ----\n",
    "fig, ax1 = plt.subplots(figsize=(12,5))\n",
    "bars = ax1.bar(x, top_percents, color=\"steelblue\", label=\"% bit=1\")\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(top_idx, rotation=90)\n",
    "ax1.set_xlabel(\"Fingerprint bit index\")\n",
    "ax1.set_ylabel(\"Percentage of molecules activating this bit\")\n",
    "ax1.yaxis.set_major_formatter(PercentFormatter())\n",
    "ax1.set_title(f\"Top {k} most frequent fingerprint bits (sorted, %) + mean(y|bit=1) ± σ\")\n",
    "\n",
    "# Secondary axis for continuous y\n",
    "ax2 = ax1.twinx()\n",
    "line, = ax2.plot(x, means_on, marker=\"o\", linewidth=1.6, label=\"mean(y | bit=1)\")\n",
    "band = ax2.fill_between(x, means_on - stds_on, means_on + stds_on, alpha=0.4, label=\"±1σ\")\n",
    "\n",
    "ax2.set_ylabel(\"y (mean ± σ for molecules with bit=1)\")\n",
    "\n",
    "# Legends: combine handles from both axes\n",
    "handles1, labels1 = ax1.get_legend_handles_labels()\n",
    "handles2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(handles1 + handles2, labels1 + labels2, loc=\"upper left\")\n",
    "\n",
    "# Add headroom so images/titles don’t collide (optional)\n",
    "ymax_pct = top_percents.max() if top_percents.size else 0\n",
    "ax1.set_ylim(0, ymax_pct * 1.5 if ymax_pct > 0 else 1)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4- What are the bits?\n",
    "\n",
    "Below we show the atom-environment pairs that have activated the different bits.\n",
    "\n",
    "We show the most freuquent bits"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "import io\n",
    "from PIL import Image as PilImage\n",
    "\n",
    "# --- Helper: convert RDKit Mol to PIL image with atom indices and highlight ---\n",
    "def mol_to_img_with_highlight(mol, center_atom, size=(200,200)):\n",
    "    drawer = rdMolDraw2D.MolDraw2DCairo(size[0], size[1])\n",
    "    opts = drawer.drawOptions()\n",
    "    opts.addAtomIndices = True\n",
    "    opts.bondLineWidth = 2\n",
    "    opts.padding = 0.05\n",
    "\n",
    "    # make all atoms gray by default\n",
    "    opts.useBWAtomPalette()\n",
    "\n",
    "    # highlight center atom in bright yellow\n",
    "    atom_colors = {center_atom: (1.0, 1.0, 0.0)}\n",
    "\n",
    "    rdMolDraw2D.PrepareAndDrawMolecule(\n",
    "        drawer, mol, highlightAtoms=[center_atom], highlightAtomColors=atom_colors\n",
    "    )\n",
    "    drawer.FinishDrawing()\n",
    "    return PilImage.open(io.BytesIO(drawer.GetDrawingText()))\n",
    "\n",
    "\n",
    "# --- Helper: overlay molecule image above a bar ---\n",
    "def add_mol_image(ax, mol, center_atom, x, y, zoom=0.4):\n",
    "    if mol is None:\n",
    "        return\n",
    "    img = mol_to_img_with_highlight(mol, center_atom=center_atom, size=(180,180))\n",
    "    im = OffsetImage(img, zoom=zoom)\n",
    "    ab = AnnotationBbox(im, (x,y), frameon=False, xybox=(0,40),\n",
    "                        xycoords='data', boxcoords=\"offset points\", pad=0)\n",
    "    ax.add_artist(ab)\n",
    "\n",
    "# --- Main function: plot top-k bits with representative substructures ---\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "def plot_bits_with_substructures(X, mols, bitinfos, start=0, k=10):\n",
    "    n_mols = X.shape[0]\n",
    "    bit_counts = X.sum(axis=0)\n",
    "\n",
    "    # Rank all bits by frequency (descending)\n",
    "    all_idx = np.argsort(-bit_counts)\n",
    "    all_counts = bit_counts[all_idx]\n",
    "\n",
    "    # Select window [start : start+k]\n",
    "    top_idx = all_idx[start:start+k]\n",
    "    top_counts = all_counts[start:start+k]\n",
    "    top_percents = (top_counts / n_mols) * 100.0\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    x = range(k)\n",
    "    ax.bar(x, top_percents, color=\"steelblue\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(top_idx, rotation=90)\n",
    "    ax.set_xlabel(\"Fingerprint bit index\")\n",
    "    ax.set_ylabel(\"Percentage of molecules activating this bit\")\n",
    "    ax.set_title(f\"Bits ranked {start+1}–{start+k} with representative substructures (% of molecules)\")\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter())\n",
    "\n",
    "    if top_percents.max() < 1:\n",
    "      from matplotlib.ticker import FuncFormatter\n",
    "      ax.yaxis.set_major_formatter(FuncFormatter(lambda v, pos: f\"{v:.2f}\".rstrip('0').rstrip('.') + '%'))\n",
    "    # Increase y-limit for images\n",
    "    ylim_max = (top_percents.max() if len(top_percents) else 0) * 1.5\n",
    "    ax.set_ylim(0, ylim_max if ylim_max > 0 else 1)\n",
    "\n",
    "    # Overlay substructure images at % heights\n",
    "    for i, bit in enumerate(top_idx):\n",
    "        for mol, info in zip(mols, bitinfos):\n",
    "            if bit in info:\n",
    "                atom_idx, rad = info[bit][0]\n",
    "                env = Chem.FindAtomEnvironmentOfRadiusN(mol, rad, atom_idx)\n",
    "                if not env:  # expand to radius=1 if empty\n",
    "                    env = Chem.FindAtomEnvironmentOfRadiusN(mol, 1, atom_idx)\n",
    "                atom_map = {}\n",
    "                submol = Chem.PathToSubmol(mol, env, atomMap=atom_map)\n",
    "                center_atom_submol = atom_map.get(atom_idx, 0)\n",
    "                add_mol_image(ax, submol, center_atom=center_atom_submol, x=i, y=top_percents[i])\n",
    "                break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Usage ---\n",
    "k = 10\n",
    "plot_bits_with_substructures(X_train, mols, bitinfos, k=k)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And the least frequent bits"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_bits_with_substructures(X_train, mols, bitinfos, start=nBits-k, k=k)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Random forest regression\n",
    "\n",
    "We have spent quite the time with the data and we have been seeing the molecular world by the eyes of our model.\n",
    "\n",
    "Now, its time to give the space for our model to learn!\n",
    "\n",
    "We will use a simple non-linear model that will try to figure out how to arrange, subset, and manouver these bits to make sensible predictions."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test (MSE): {mse}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Understanding the performance\n",
    "\n",
    "Above, the Mean Squared Error (MSE) is printed, and it's 1.82 LogS.\n",
    "\n",
    "But honestly, this value is quite cryptic! One can do more to make performance easier to understand.\n",
    "\n",
    "Below, we show two plots.\n",
    "\n",
    "\n",
    "\n",
    "1.   The top one is the distributions of the predicted and the true values. And this plot shows that the model captured the width of the true value to some extent. But, it was more keen to make predictions at the center of the distribution.\n",
    "2.   The bottom plot shows the alignment betwen predicitons and truth with varying metrics.\n",
    "  - The pearson correlation (r) measures whether a model captured the trend in the data.\n",
    "    - range = [-1, 1]\n",
    "    - The higher the value the better.\n",
    "    - Here, it is quite high (this is shown by the semi linear shape the scatter plot has)\n",
    "  - The coeffecient of detemination ($R^2$) metric measures how much of the variance is explained.\n",
    "    - Range = (-∞, 1]\n",
    "    - The higher the value the better\n",
    "    - Here, it is also a bit high (look at the distributions, they have quite a similar shape)\n",
    "  - The mean absolute error (MAE) measures how far the predictions were from the truth regardless of the direction (i.e., doesn't matter if it over or under-predicts).\n",
    "    - Range is data dependant\n",
    "    - Interpretable by an endpoint expert\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- Shared helper ----\n",
    "def compute_metrics(yp, yt):\n",
    "    \"\"\"Return r, R², MAE, RMSE for predicted vs true arrays.\"\"\"\n",
    "    if yp.size < 2:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    r = np.corrcoef(yp, yt)[0, 1]\n",
    "    ss_res = np.sum((yt - yp) ** 2)\n",
    "    ss_tot = np.sum((yt - yt.mean()) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot if ss_tot > 0 else np.nan\n",
    "    mae = np.mean(np.abs(yt - yp))\n",
    "    rmse = np.sqrt(np.mean((yt - yp) ** 2))\n",
    "    return r, r2, mae, rmse\n",
    "\n",
    "\n",
    "# ---- Plot distributions + scatter ----\n",
    "def plot_distributions_and_scatter(y_pred, y_test):\n",
    "    mask = np.isfinite(y_pred) & np.isfinite(y_test)\n",
    "    yp, yt = np.asarray(y_pred)[mask], np.asarray(y_test)[mask]\n",
    "\n",
    "    r, r2, mae, rmse = compute_metrics(yp, yt)\n",
    "\n",
    "    lo = min(yp.min(), yt.min())\n",
    "    hi = max(yp.max(), yt.max())\n",
    "    bins = np.histogram_bin_edges(np.concatenate([yt, yp]), bins=\"auto\")\n",
    "\n",
    "    fig, (ax_top, ax_bottom) = plt.subplots(2, 1, figsize=(7, 10), constrained_layout=True)\n",
    "\n",
    "    # (Top) distributions\n",
    "    ax_top.hist(yt, bins=bins, alpha=0.6, label=\"True\", edgecolor=\"black\", linewidth=0.5)\n",
    "    ax_top.hist(yp, bins=bins, alpha=0.6, label=\"Pred\", edgecolor=\"black\", linewidth=0.5)\n",
    "    ax_top.set_title(\"True vs Predicted Distributions\")\n",
    "    ax_top.set_xlabel(\"y\")\n",
    "    ax_top.set_ylabel(\"Count\")\n",
    "    ax_top.legend()\n",
    "    ax_top.grid(True, alpha=0.2)\n",
    "\n",
    "    # (Bottom) scatter\n",
    "    ax_bottom.scatter(yp, yt, s=12, alpha=0.7)\n",
    "    ax_bottom.plot([lo, hi], [lo, hi], 'r--', linewidth=1)\n",
    "    ax_bottom.set_xlabel(\"predicted value\")\n",
    "    ax_bottom.set_ylabel(\"true value\")\n",
    "    ax_bottom.set_title(\"Predicted vs. True\")\n",
    "    ax_bottom.set_xlim(lo, hi)\n",
    "    ax_bottom.set_ylim(lo, hi)\n",
    "    ax_bottom.grid(True, alpha=0.2)\n",
    "\n",
    "    # metrics annotation\n",
    "    text = f\"r = {r:.3f}\\nR² = {r2:.3f}\\nMAE = {mae:.3f}\"\n",
    "    ax_bottom.text(0.02, 0.98, text, transform=ax_bottom.transAxes,\n",
    "                   ha='left', va='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, linewidth=0.5))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_distributions_and_scatter(y_pred, y_test)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What about practicality?\n",
    "\n",
    "Usually, people in pharma do not interact with molecules in the full ranges of -12 to 2 LogS, but rather, in the range of -6 to -3 [[Ash *et. al.*, 2025]](https://pubs.acs.org/doi/10.1021/acs.jcim.5c01609) (i.e., between micro and milli mole/litre).\n",
    "\n",
    "So, If a pharmacist uses this model, they will be mostly interested in predictions in this practical range. So, Howe does our model perform there?\n",
    "\n",
    "The below figure shows the overall performance but highlights the practical range.\n",
    "\n",
    "One can see from the highlighted part that the predictions are quite scattered.\n",
    "\n",
    "By looking at the metrics:\n",
    "- The pearson correlation r dropped almost by half\n",
    "- The $R^2$ dropped dramatically to below zero\n",
    "- The MAE remained almost the same.\n",
    "\n",
    "How to interpret these differences?\n",
    "- If the pharmacist was already satisfied with a margin of error of 0.9 LogS, then nothing changes.\n",
    "- If the pharmacist is interested in predicting the true values as close as possible, then $R^2$ is saying that this is currently not possible. The model is not good at predicting a correct value at this range.\n",
    "- But r is saying that, while the model is not predicting the exact true value, it still somewhat learns the trend (i.e., when a molecule will be more vs. less soluble)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---- Plot scatter with highlighted practical range ----\n",
    "def plot_scatter_with_range(y_pred, y_test, low=-6, high=-3):\n",
    "    mask = np.isfinite(y_pred) & np.isfinite(y_test)\n",
    "    yp, yt = np.asarray(y_pred)[mask], np.asarray(y_test)[mask]\n",
    "\n",
    "    r, r2, mae, rmse = compute_metrics(yp, yt)\n",
    "\n",
    "    mask_range = (yt >= low) & (yt <= high)\n",
    "    yp_sub, yt_sub = yp[mask_range], yt[mask_range]\n",
    "    r_s, r2_s, mae_s, rmse_s = compute_metrics(yp_sub, yt_sub)\n",
    "\n",
    "    lo = min(yp.min(), yt.min())\n",
    "    hi = max(yp.max(), yt.max())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6.8, 6.2))\n",
    "    ax.axhspan(low, high, facecolor='tab:orange', alpha=0.08, zorder=0)\n",
    "\n",
    "    ax.scatter(yp, yt, s=10, alpha=0.25, color='0.55', label=f'All (n={len(yt)})')\n",
    "    ax.scatter(yp_sub, yt_sub, s=22, alpha=0.9, color='tab:orange',\n",
    "               edgecolor='k', linewidth=0.3,\n",
    "               label=f'In range [{low}, {high}] (n={len(yt_sub)})')\n",
    "\n",
    "    ax.plot([lo, hi], [lo, hi], 'r--', linewidth=1, label='y = x')\n",
    "\n",
    "    ax.set_xlabel('predicted value')\n",
    "    ax.set_ylabel('true value')\n",
    "    ax.set_title('Predicted vs. True (highlighted practical TRUE range)')\n",
    "    ax.set_xlim(lo, hi)\n",
    "    ax.set_ylim(lo, hi)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "\n",
    "    text = (\n",
    "        f\"Overall (n={len(yt)}):\\n\"\n",
    "        f\" r = {r:.3f}   R² = {r2:.3f}\\n\"\n",
    "        f\" MAE = {mae:.3f}   RMSE = {rmse:.3f}\\n\"\n",
    "        f\"\\nSubset [{low}, {high}] (n={len(yt_sub)}):\\n\"\n",
    "        f\" r = {r_s:.3f}   R² = {r2_s:.3f}\\n\"\n",
    "        f\" MAE = {mae_s:.3f} \"\n",
    "    )\n",
    "    ax.text(0.02, 0.98, text, transform=ax.transAxes,\n",
    "            ha='left', va='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.85, linewidth=0.5))\n",
    "\n",
    "    ax.legend(loc='lower right', frameon=True, framealpha=0.85)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_scatter_with_range(y_pred, y_test, low=-6, high=-3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Interpreting the forest\n",
    "\n",
    "The random forest algorithm is cool in the sense that it can assign an importance value for each bit.\n",
    "\n",
    "This depends on how much each bit helped in reducing the variability in the data when used for splitting.\n",
    "\n",
    "The below figure shows the most informative bits and displays their atom and environment as well for clarity."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_top_rf_bits_with_substructures(importances, bit_idx, mols, bitinfos, k=10):\n",
    "    order = np.argsort(importances)[::-1]\n",
    "    top_idx = order[:k]\n",
    "    top_bits = bit_idx[top_idx]\n",
    "    top_imps = importances[top_idx]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    x = range(k)\n",
    "    ax.bar(x, top_imps, color=\"darkorange\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(top_bits, rotation=90)\n",
    "    ax.set_xlabel(\"Morgan bit index\")\n",
    "    ax.set_ylabel(\"RF feature importance\")\n",
    "    ax.set_title(f\"Top {k} RF feature importances (Morgan bits)\")\n",
    "\n",
    "    ylim_max = (top_imps.max() if len(top_imps) else 0) * 1.3\n",
    "    ax.set_ylim(0, ylim_max if ylim_max > 0 else 1)\n",
    "\n",
    "    # Try to overlay substructure images\n",
    "    for i, bit in enumerate(top_bits):\n",
    "        placed = False\n",
    "        for mol, info in zip(mols, bitinfos):\n",
    "            if bit in info:\n",
    "                atom_idx, rad = info[bit][0]\n",
    "                env = Chem.FindAtomEnvironmentOfRadiusN(mol, rad, atom_idx)\n",
    "                if not env:  # fallback if lone atom\n",
    "                    env = Chem.FindAtomEnvironmentOfRadiusN(mol, 1, atom_idx)\n",
    "\n",
    "                atom_map = {}\n",
    "                submol = Chem.PathToSubmol(mol, env, atomMap=atom_map)\n",
    "\n",
    "                if atom_idx in atom_map:  # ✅ only highlight if mapping exists\n",
    "                    center_atom_submol = atom_map[atom_idx]\n",
    "                    add_mol_image(ax, submol, center_atom=center_atom_submol,\n",
    "                                  x=i, y=top_imps[i])\n",
    "                    placed = True\n",
    "                    break\n",
    "        if not placed:\n",
    "            print(f\"⚠️ Skipping bit {bit} (could not map atom index)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Usage ---\n",
    "importances = rf_model.feature_importances_\n",
    "bit_idx = np.arange(X_train.shape[1])\n",
    "\n",
    "plot_top_rf_bits_with_substructures(importances, bit_idx, mols, bitinfos, k=10)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Closing the circle - going back to feature analysis\n",
    "\n",
    "At the beginning, we spent quite the time looking at the data and seeing the world through the eyes of the model.\n",
    "\n",
    "Is there direct mappings between the way we interpreted the model's world, and the way the model intepreted it?\n",
    "\n",
    "--\n",
    "\n",
    "We already had a plot that showes the variance in LogS values per activated bit. And we hoped to see some bits that would have highly soluble or highly insluble molecules, then they will be quite informaive ones.\n",
    "\n",
    "But we did not really find many of such bits.\n",
    "\n",
    "--\n",
    "\n",
    "Now, the RF importance assignment is the equivelant of our variance analysis.\n",
    "\n",
    "We can check whether there was any correlation betwen our thinking and the model's thinking.\n",
    "\n",
    "The below plot shows for each bit the variance of the molecules that activated it vs. the imporntance assigned to it by the RF algorithm.\n",
    "\n",
    "I would hope that bits with low variance correlate with high importance by the model.\n",
    "\n",
    "--\n",
    "\n",
    "And while the correlation did not show up. At least we see that the most informative features were more on the left side of the plot (i.e., the part with smaller variance)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: compute variance per bit ---\n",
    "bit_variances = {}\n",
    "for b in range(X_train.shape[1]):\n",
    "    mask = X_train[:, b].astype(bool)\n",
    "    y_on = y_train[mask]\n",
    "    if y_on.size > 1:\n",
    "        bit_variances[b] = np.var(y_on, ddof=1)   # sample variance\n",
    "    else:\n",
    "        bit_variances[b] = np.nan\n",
    "\n",
    "# --- Step 2: collect into dataframe with importances ---\n",
    "bit_idx = np.arange(X_train.shape[1])\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"bit\": bit_idx,\n",
    "    \"importance\": importances,\n",
    "    \"variance\": [bit_variances[b] for b in bit_idx]\n",
    "}).dropna(subset=[\"variance\"])\n",
    "\n",
    "# --- Step 3: rank both dimensions ---\n",
    "df[\"importance_rank\"] = df[\"importance\"].rank(ascending=False, method=\"min\")\n",
    "df[\"variance_rank\"]   = df[\"variance\"].rank(ascending=True, method=\"min\")\n",
    "\n",
    "# --- Step 4: define overlap sets ---\n",
    "top_importance = df.nsmallest(20, \"importance_rank\")\n",
    "low_variance   = df.nsmallest(20, \"variance_rank\")\n",
    "intersection   = pd.merge(top_importance, low_variance, on=\"bit\", suffixes=(\"_imp\", \"_var\"))\n",
    "\n",
    "print(\"Bits that are both high-importance and low-variance:\")\n",
    "print(intersection[[\"bit\", \"importance_imp\", \"variance_imp\",\n",
    "                    \"importance_rank_imp\", \"variance_rank_imp\"]])\n",
    "\n",
    "# --- Step 5: scatter plot ---\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(df[\"variance\"], df[\"importance\"], s=14, alpha=0.6, label=\"All bits\")\n",
    "if not intersection.empty:\n",
    "    plt.scatter(intersection[\"variance\"], intersection[\"importance\"],\n",
    "                color=\"red\", s=40, label=\"Top importance & low variance\")\n",
    "\n",
    "plt.xlabel(\"Variance of y | bit=1\")\n",
    "plt.ylabel(\"RF Feature Importance\")\n",
    "plt.title(\"Importance vs Variance of Morgan bits\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "In the lecture, you got exposed to many algorithms and models that one can pick and try. However, most of this notebook was about looking deeper at the steps of training a model including:\n",
    "- Seeing the world through the eyes of the model\n",
    "- Trying to anticipate in advance what is helpful and what is not\n",
    "- Spending time and effort to contextualize the model's ouput through\n",
    "  - Proper performance visualization\n",
    "  - Interpretability analysis\n",
    "  - Practicality lense\n",
    "- Finally, going back to where we started to see how much were we accurate in our preliminary assumptions.\n",
    "\n",
    "Using an ML library and training a model is an extremely simple thing nowadays.\n",
    "\n",
    "But this is probably not the goal!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# More hands-on notebooks?\n",
    "\n",
    "Check out the [TeachOpenCADD](https://volkamerlab.org/projects/teachopencadd/) collection from the Volkamer lab!\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " # More philosophically-driven hands-on?\n",
    "\n",
    "Check [The diaries of a cheminformatics PhD](https://afnan-sultan.github.io/year-archive/) blog by me, Afnan Sultan!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Supplementary material - More models!\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Neural networks\n",
    "\n",
    "### Multi-layer perceptron (MLP) on fingerprints"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tqdm\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SolubilityDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        self.fingerprints = torch.tensor(list(map(smiles2fp, split['Drug'])), dtype=torch.float)\n",
    "        self.labels = torch.tensor(split['Y'], dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fingerprint = self.fingerprints[idx]\n",
    "        label = self.labels[idx]\n",
    "        return fingerprint, label\n",
    "\n",
    "train_dataset = SolubilityDataset(split['train'])\n",
    "valid_dataset = SolubilityDataset(split['valid'])\n",
    "test_dataset = SolubilityDataset(split['test'])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SolubilityNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SolubilityNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SolubilityNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train_step(loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for fingerprints, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(fingerprints)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(labels)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def test_step(loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for fingerprints, labels in valid_dataloader:\n",
    "            outputs = model(fingerprints)\n",
    "            valid_loss += criterion(outputs.squeeze(), labels).item()\n",
    "    valid_loss /= len(valid_dataloader)\n",
    "    return valid_loss\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_step(train_dataloader)\n",
    "    valid_loss = test_step(valid_dataloader)\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:03d}, Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for fingerprints, labels in test_dataloader:\n",
    "            outputs = model(fingerprints)\n",
    "            test_loss += criterion(outputs.squeeze(), labels).item()\n",
    "    test_loss /= len(test_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with torch.no_grad():\n",
    "    plt.scatter(model(test_dataloader.dataset.fingerprints).flatten(), test_dataloader.dataset.labels, marker='.')\n",
    "plt.plot([-10, 2], [-10, 2], 'r--')\n",
    "plt.ylabel('true value')\n",
    "plt.xlabel('predicted value')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Graph neural network (GNN)\n",
    "\n",
    "First, we need to create graph structures out of the SMILES string. For this, we use the from_smiles utility in pytorch-geometric. This way, we create one `Data` object for each molecule. We additionally annotate each molecule with the solubility value (as attribute `y`)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch_geometric.utils import from_smiles\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "def process_smiles(row):\n",
    "    data = from_smiles(row.Drug)\n",
    "    data.x = data.x.to(torch.float)\n",
    "    data.y = torch.tensor(row.Y, dtype=torch.float)\n",
    "    return data\n",
    "\n",
    "train_dataloader = DataLoader(list(map(process_smiles, split['train'].itertuples())), batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(list(map(process_smiles, split['valid'].itertuples())), batch_size=32)\n",
    "test_dataloader = DataLoader(list(map(process_smiles, split['test'].itertuples())), batch_size=32)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's take a look at an example molecule and its pytorch-geometric encoding."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "smiles = split['train']['Drug'][0]\n",
    "Chem.MolFromSmiles(smiles)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This graph is represented as a `Data` object. The nodes and its features are stored in `x` with shape `(n_nodes, n_features)`. The bond structure is given as an adjacency list in `edge_index`. Edge features can be found in `edge_attr`."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = from_smiles(split['train']['Drug'][0])\n",
    "data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The atom featurization uses some basic features with torch-geometric computes using rdkit."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# excerpt from torch_geometrics molecular featurization\n",
    "\n",
    "# for atom in mol.GetAtoms():\n",
    "#     row: List[int] = []\n",
    "#     row.append(x_map['atomic_num'].index(atom.GetAtomicNum()))\n",
    "#     row.append(x_map['chirality'].index(str(atom.GetChiralTag())))\n",
    "#     row.append(x_map['degree'].index(atom.GetTotalDegree()))\n",
    "#     row.append(x_map['formal_charge'].index(atom.GetFormalCharge()))\n",
    "#     row.append(x_map['num_hs'].index(atom.GetTotalNumHs()))\n",
    "#     row.append(x_map['num_radical_electrons'].index(atom.GetNumRadicalElectrons()))\n",
    "#     row.append(x_map['hybridization'].index(str(atom.GetHybridization())))\n",
    "#     row.append(x_map['is_aromatic'].index(atom.GetIsAromatic()))\n",
    "#     row.append(x_map['is_in_ring'].index(atom.IsInRing()))\n",
    "#     xs.append(row)\n",
    "\n",
    "data.x"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch_geometric.nn import global_mean_pool, GCNConv\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as Fun\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU\n",
    "\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "\n",
    "import torch.nn.functional as Fun\n",
    "\n",
    "\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    \"\"\"Graph Isomorphism Network class with 3 GINConv layers and 2 linear layers\"\"\"\n",
    "\n",
    "    def __init__(self, dim_h):\n",
    "        \"\"\"Initializing GIN class\n",
    "\n",
    "        Args:\n",
    "            dim_h (int): the dimension of hidden layers\n",
    "        \"\"\"\n",
    "        super(GIN, self).__init__()\n",
    "\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(9, dim_h), ReLU(), Linear(dim_h, dim_h), ReLU())\n",
    "        )\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(\n",
    "                Linear(dim_h, dim_h), ReLU(), Linear(dim_h, dim_h), ReLU()\n",
    "            )\n",
    "        )\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(\n",
    "                Linear(dim_h, dim_h), ReLU(), Linear(dim_h, dim_h), ReLU()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.lin1 = Linear(dim_h, dim_h)\n",
    "        self.lin2 = Linear(dim_h, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        batch = data.batch\n",
    "\n",
    "        # Node embeddings\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv3(h, edge_index)\n",
    "\n",
    "        # Graph-level readout\n",
    "        h = global_add_pool(h, batch)\n",
    "\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = Fun.dropout(h, p=0.1, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "model = GIN(32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out.squeeze(), data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(train_dataloader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        out = model(data)\n",
    "        loss = criterion(out.squeeze(), data.y)\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss = train()\n",
    "    valid_loss = test(valid_dataloader)\n",
    "    print(f'Epoch: {epoch + 1:03d}, Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        outputs = model(data)\n",
    "        test_loss += criterion(outputs.squeeze(), data.y).item()\n",
    "test_loss /= len(test_dataloader)\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with torch.no_grad():\n",
    "  predictions, ground_truth = list(), list()\n",
    "  for data in test_dataloader:\n",
    "      outputs = model(data)\n",
    "      predictions.extend(list(outputs.squeeze()))\n",
    "      ground_truth.extend(list(data.y))\n",
    "plt.scatter(predictions, ground_truth, marker='.')\n",
    "plt.ylabel('true value')\n",
    "plt.xlabel('predicted value')\n",
    "plt.plot([-10, 2], [-10, 2], 'r--')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
