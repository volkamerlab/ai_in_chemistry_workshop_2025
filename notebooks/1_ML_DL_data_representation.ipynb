{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://gist.github.com/Afnan-Sultan/111fb1376659d526f8b57ca45dd8581a#file-session_1-ipynb",
     "timestamp": 1758532058908
    }
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Important Note\n",
    "\n",
    "If you're running this notebook on Google Colab, it will run a lot faster if you set the runtime type to **T4 GPU**.\n",
    "You can do this from the **Runtime** menu.\n",
    "\n",
    "Runtime->Change Runtime Type->T4 GPU\n"
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-22T11:08:18.800479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install PyTDC\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "!pip install torch-geometric torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "# !pip install torch-geometric torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-1.13.0+cu116.html"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyTDC\r\n",
      "  Downloading pytdc-1.1.15.tar.gz (154 kB)\r\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m154.2/154.2 kB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting accelerate==0.33.0 (from PyTDC)\r\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting dataclasses<1.0,>=0.6 (from PyTDC)\r\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting datasets<2.20.0 (from PyTDC)\r\n",
      "  Downloading datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting evaluate==0.4.2 (from PyTDC)\r\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Collecting fuzzywuzzy<1.0,>=0.18.0 (from PyTDC)\r\n",
      "  Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Collecting huggingface_hub<1.0,>=0.20.3 (from PyTDC)\r\n",
      "  Downloading huggingface_hub-0.35.0-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.4 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from PyTDC) (1.26.4)\r\n",
      "Collecting openpyxl<4.0.0,>=3.0.10 (from PyTDC)\r\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting pandas<3.0.0,>=2.1.4 (from PyTDC)\r\n",
      "  Downloading pandas-2.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (91 kB)\r\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m91.2/91.2 kB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from PyTDC) (2.31.0)\r\n",
      "Requirement already satisfied: scikit-learn>=1.2.2 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from PyTDC) (1.3.2)\r\n",
      "Collecting seaborn<1.0.0,>=0.12.2 (from PyTDC)\r\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /Users/afnan_sultan/miniconda3/lib/python3.12/site-packages (from PyTDC) (4.65.0)\r\n",
      "Collecting transformers<4.51.0,>=4.43.0 (from PyTDC)\r\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\r\n",
      "INFO: pip is looking at multiple versions of pytdc to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting PyTDC\r\n",
      "  Downloading pytdc-1.1.14.tar.gz (151 kB)\r\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m151.3/151.3 kB\u001B[0m \u001B[31m8.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting scikit-learn==1.2.2 (from PyTDC)\r\n",
      "  Downloading scikit-learn-1.2.2.tar.gz (7.3 MB)\r\n",
      "\u001B[2K     \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m7.3/7.3 MB\u001B[0m \u001B[31m21.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25l\\"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The most important aspect: Well-curated data\n",
    "## Therapeutics Data Commons: An easily accessible source\n",
    "- lots of standard data sets on [tdcommons.ai](https://tdcommons.ai)\n",
    "- easy data splitting (random, scaffold, cold_*)\n",
    "\n",
    "## A solubility dataset: AqSolDB\n",
    "- made by [Sorkun, Khetan, Er (2019)](https://www.nature.com/articles/s41597-019-0151-1)\n",
    "- compound data set (merged 9 data sets)\n",
    "- handling of duplicates and multiple measurements:\n",
    "  - more than 2: select the one closest to the mean\n",
    "  - 2 measurements: select the one closest to ALOGPS prediction"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tdc.single_pred import ADME\n",
    "data = ADME(name = 'Solubility_AqSolDB')\n",
    "split = data.get_split(method='random')\n",
    "data.print_stats()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "split['train']"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Label distribution\n",
    "\n",
    "It's important to see the range of our data, the size, and the distribution.\n",
    "\n",
    "This gives us an idea about where most of the data are clustered and whether our molecules are biased to a specific range.\n",
    "\n",
    "Below we see our data mostly between -9 ans 2.5 LogS, but we still see some few molecules that are scoring lower LogS values."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# concatenate train + test into one Series\n",
    "y_all = pd.concat([split['train']['Y'], split['test']['Y']]).dropna()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "\n",
    "# KDE for all data\n",
    "sns.kdeplot(y_all, ax=ax, fill=True, alpha=0.3, color=\"tab:blue\", label=\"All data\")\n",
    "\n",
    "# twin axis for boxplot\n",
    "ax2 = ax.twinx()\n",
    "pos = 0\n",
    "ax2.boxplot(y_all, vert=False, positions=[pos], widths=0.12, patch_artist=True,\n",
    "            boxprops=dict(facecolor=\"none\", edgecolor=\"tab:blue\"),\n",
    "            medianprops=dict(color=\"tab:blue\"))\n",
    "ax2.plot(np.mean(y_all), pos, marker='^', color='red', markersize=8, zorder=3)\n",
    "\n",
    "# clean up the twin axis\n",
    "ax2.set_axis_off()\n",
    "\n",
    "# labels and title\n",
    "ax.set_xlabel(\"LogS\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_title(f\"Y distribution (All data, n={len(y_all)})\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Featurization - The model doesn't see a molecule, it sees a *representation* of a molecule!\n",
    "- __rdkit__ is the main tool for working with molecules\n",
    "- `rdFingerprintGenerator` can  produce a multitude of fingerprints.\n",
    "- We use the Morgan fingerprint approach to represet our molecules as a bit vector `GetMorganFingerprintAsBitVect`\n",
    "\n",
    "## But... what exactly is this representation, and how it is generated?\n",
    "\n",
    "- It's a way to convert a molecule into a binary vectors of 0s and 1s\n",
    "- Each bit corresponds to an atom in an environment such as\n",
    "  - Atomic number and connectivity/valence cues.\n",
    "  - Hydrogen information\n",
    "  - Formal charge.\n",
    "  - Aromaticity flag.\n",
    "  - Ring membership\n",
    "  - Chirality (optional)\n",
    "- The environment cues form a integer of 32 bits, and this integer is the identity of this atom in this environment[$^1$].\n",
    "  - This id gets hashed to map to a single bit index in the bit vector.\n",
    "    - The equation to get the bit index is `√¨d % nBits`\n",
    "- An activated bit (i.e., bit = 1), means that this atom in this environment is present in this molecule.\n",
    "- The environment is defined circularly by choosing a radius to decide how many connecting atoms to consider\n",
    "  - The radius is user defined\n",
    "  - When using raius = n, the algorithm automatically calculates radius = 0, 0+1, 0+1+2, ... , 0+1+...+n-1+n\n",
    "- The length of the vector is user defined\n",
    "  - Longer vector = more environments to store.\n",
    "    - But it also means that many bits will be zeros in most of the molecules because not all atom-environment pairs exist in all molecules (i.e., the vectors become sparse)\n",
    "\n",
    "The below animation walks you through the construction of this algorithm.\n",
    "\n",
    "Pay attention to bit at index 1 in the two molecules, and see when (and how many times) it gets activated.\n",
    "- **Is it always the same atom-environment pair that activates it?**\n",
    "\n",
    "Pay attention to index 1 in the Caffeine example\n",
    "- **Does it get activated each time by the same atom-environment pair?**\n",
    "\n",
    "---\n",
    "\n",
    "[$^1$]: check this atom-enviroment coding for at `O` in an `O=C` environment.\n",
    "- Number of non-hydrogen immediate neighbors = 3\n",
    "- Valency minus the number of connected hydrogens = 4\n",
    "- Atomic number = 6\n",
    "- Atomic mass = 12\n",
    "- Atomic charge = 0\n",
    "- Number of attached hydrogens = 0\n",
    "- Atom is a part of at least one ring = 0\n",
    "\n",
    "`atom-environment pair ID = hash((3, 4, 6, 12, 0, 0, 0))`"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.rdMolDescriptors import GetMorganFingerprintAsBitVect\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator, AdditionalOutput\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image as PilImage\n",
    "from IPython.display import HTML\n",
    "\n",
    "# --- Example molecules ---\n",
    "examples = [\n",
    "    (\"Example #1: Phenol\", \"c1ccccc1O\"),\n",
    "    (\"Example #2: Caffeine\", \"Cn1cnc2c1c(=O)n(c(=O)n2C)C\")\n",
    "]\n",
    "\n",
    "# --- Parameters ---\n",
    "radius = 2\n",
    "nBits = 32\n",
    "mfpgen_folded   = GetMorganGenerator(radius=radius, fpSize=nBits)  # folded\n",
    "mfpgen_unfolded = GetMorganGenerator(radius=radius)                # unfolded\n",
    "\n",
    "# --- Collect steps for all molecules ---\n",
    "all_steps = []\n",
    "for ex_id, (name, smi) in enumerate(examples):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    AllChem.Compute2DCoords(mol)\n",
    "\n",
    "    # folded bitInfo\n",
    "    bitInfo = {}\n",
    "    _ = GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=nBits, bitInfo=bitInfo)\n",
    "\n",
    "    # unfolded raw IDs\n",
    "    info = AdditionalOutput()\n",
    "    info.CollectBitInfoMap()\n",
    "    _ = mfpgen_unfolded.GetFingerprint(mol, additionalOutput=info)\n",
    "    bitInfoFull = info.GetBitInfoMap()  # raw env_id ‚Üí [(atom_idx, rad), ...]\n",
    "\n",
    "    for bit, infos in bitInfo.items():  # folded bits\n",
    "        for atom_idx, rad in infos:\n",
    "            env = Chem.FindAtomEnvironmentOfRadiusN(mol, rad, atom_idx)\n",
    "            atoms = {atom_idx}\n",
    "            for b in env:\n",
    "                bond = mol.GetBondWithIdx(b)\n",
    "                atoms.add(bond.GetBeginAtomIdx())\n",
    "                atoms.add(bond.GetEndAtomIdx())\n",
    "\n",
    "            # find raw env_id (32-bit)\n",
    "            env_id = None\n",
    "            for rid, tuples in bitInfoFull.items():\n",
    "                for a, r in tuples:\n",
    "                    if a == atom_idx and r == rad:\n",
    "                        env_id = rid   # raw 32-bit env ID\n",
    "                        break\n",
    "                if env_id is not None:\n",
    "                    break\n",
    "\n",
    "            all_steps.append((ex_id, name, mol, rad, atom_idx, atoms, env, bit, env_id))\n",
    "\n",
    "# sort: example first, then radius, then atom index\n",
    "all_steps.sort(key=lambda x: (x[0], x[3], x[4]))\n",
    "\n",
    "# ranges for reset per example\n",
    "ex_ranges = {}\n",
    "i = 0\n",
    "while i < len(all_steps):\n",
    "    ex_id = all_steps[i][0]\n",
    "    j = i\n",
    "    while j < len(all_steps) and all_steps[j][0] == ex_id:\n",
    "        j += 1\n",
    "    ex_ranges[ex_id] = (i, j)\n",
    "    i = j\n",
    "\n",
    "# --- Helper: draw molecule gray + highlight red ---\n",
    "def mol_to_image_gray_base_with_highlight(mol, atoms=None, bonds=None, center_atom=None,\n",
    "                                          size=(500, 500),\n",
    "                                          gray_rgb=(160, 160, 160), black_thresh=40):\n",
    "    m = Chem.Mol(mol)\n",
    "    drawer = rdMolDraw2D.MolDraw2DCairo(size[0], size[1])\n",
    "    opts = drawer.drawOptions()\n",
    "    opts.padding = 0.02\n",
    "    opts.bondLineWidth = 2\n",
    "    if hasattr(opts, \"useBWAtomPalette\"):\n",
    "        opts.useBWAtomPalette()\n",
    "\n",
    "    atom_colors = {}\n",
    "    if atoms:\n",
    "        for a in atoms:\n",
    "            if a == center_atom:\n",
    "                atom_colors[a] = (1.0, 1.0, 0.0)   # yellow center atom\n",
    "            else:\n",
    "                atom_colors[a] = (1.0, 0.0, 0.0)   # red neighbors\n",
    "    bond_colors = {b: (1.0, 0.0, 0.0) for b in (bonds or [])}\n",
    "\n",
    "    rdMolDraw2D.PrepareAndDrawMolecule(\n",
    "        drawer, m,\n",
    "        highlightAtoms=list(atoms) if atoms else [],\n",
    "        highlightBonds=list(bonds) if bonds else [],\n",
    "        highlightAtomColors=atom_colors,\n",
    "        highlightBondColors=bond_colors,\n",
    "    )\n",
    "    drawer.FinishDrawing()\n",
    "    img = PilImage.open(io.BytesIO(drawer.GetDrawingText())).convert(\"RGBA\")\n",
    "\n",
    "    arr = np.asarray(img).copy()\n",
    "    rgb, alpha = arr[..., :3], arr[..., 3]\n",
    "    near_black = (rgb[..., 0] < black_thresh) & (rgb[..., 1] < black_thresh) & \\\n",
    "                 (rgb[..., 2] < black_thresh) & (alpha > 0)\n",
    "    arr[..., :3][near_black] = gray_rgb\n",
    "    return PilImage.fromarray(arr, mode=\"RGBA\")\n",
    "\n",
    "# --- Fingerprint panel ---\n",
    "def draw_fingerprint(ax, bit_array, highlight=None):\n",
    "    ax.clear()\n",
    "    ax.set_xlim(0, nBits)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks(range(nBits))\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(\"Fingerprint Bits\", fontsize=14, pad=8)\n",
    "    for i in range(nBits):\n",
    "        color = \"white\" if bit_array[i] == 0 else \"black\"\n",
    "        rect = Rectangle((i, 0.4), 0.9, 0.2, facecolor=color,\n",
    "                         edgecolor=\"black\", linewidth=0.8)\n",
    "        ax.add_patch(rect)\n",
    "    if highlight is not None:\n",
    "        rect = Rectangle((highlight, 0.4), 0.9, 0.2, facecolor=\"red\",\n",
    "                         edgecolor=\"black\", linewidth=1.2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "# --- Animation setup ---\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "gs = fig.add_gridspec(2, 1, height_ratios=[2.5, 1])\n",
    "ax_mol = fig.add_subplot(gs[0])\n",
    "ax_fp  = fig.add_subplot(gs[1])\n",
    "\n",
    "bit_array = np.zeros(nBits, dtype=int)\n",
    "\n",
    "def update(frame):\n",
    "    ex_id, ex_name, mol, rad, atom_idx, atoms, bonds, bit, env_id = all_steps[frame]\n",
    "\n",
    "    # reset bits for this example only\n",
    "    start, _ = ex_ranges[ex_id]\n",
    "    bit_array[:] = 0\n",
    "    for _, _, _, _, _, _, _, b, _ in all_steps[start:frame+1]:\n",
    "        bit_array[b] = 1\n",
    "\n",
    "    # clear mol panel\n",
    "    ax_mol.clear()\n",
    "    img = mol_to_image_gray_base_with_highlight(mol, atoms=atoms,\n",
    "                                                bonds=bonds, center_atom=atom_idx,\n",
    "                                                size=(500, 500))\n",
    "    ax_mol.imshow(img)\n",
    "    ax_mol.axis(\"off\")\n",
    "    ax_mol.set_title(f\"{ex_name} | Atom {atom_idx}, Radius {rad}\", fontsize=16, pad=15)\n",
    "\n",
    "    # small table to right of molecule\n",
    "    ax_table = ax_mol.inset_axes([-0.8, -0.6, 0.9, 1.2])  # X, y, width, height\n",
    "    ax_table.axis(\"off\")\n",
    "    table_data = [[atom_idx, rad, env_id, env_id % nBits]]\n",
    "    table = ax_table.table(cellText=table_data,\n",
    "                           colLabels=[\"Atom\", \"Radius\", \"id\", \"id % nBits\"],\n",
    "                           loc=\"center\", cellLoc=\"center\")\n",
    "    table.scale(1.0, 1.2)\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "\n",
    "    draw_fingerprint(ax_fp, bit_array, highlight=bit)\n",
    "\n",
    "# --- Run animation ---\n",
    "ani = FuncAnimation(fig, update, frames=len(all_steps), interval=1500, repeat=False)\n",
    "HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# Quiet rdkit warnings\n",
    "RDLogger.logger().setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "# --- setup Morgan generator ---\n",
    "nBits = 1024\n",
    "radius = 2\n",
    "mfpgen = rdFingerprintGenerator.GetMorganGenerator(radius=radius, fpSize=nBits)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data splitting\n",
    "\n",
    "We need to split our data into train and test sets so that we have some molecules to test our model on once finished training.\n",
    "\n",
    "Today we use a vanilla splitting approach, which randomly assignes molecules to train and test sets with a ratio of 80:20.\n",
    "\n",
    "We use the 80% to train the model, and the 20% to test it."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "smiles2fp = lambda smiles: mfpgen.GetFingerprintAsNumPy(Chem.MolFromSmiles(smiles))\n",
    "X_train = np.stack(list(map(smiles2fp, tqdm.tqdm(split['train']['Drug']))))\n",
    "y_train = split['train']['Y'].values\n",
    "X_test = np.stack(list(map(smiles2fp, tqdm.tqdm(split['test']['Drug']))))\n",
    "y_test = split['test']['Y'].values"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's visualize the label distribution of both train and test sets.\n",
    "\n",
    "The two distributions span similar range and shape. This tells us that our model will not be failing due to a distributional shift!\n",
    "\n",
    "If it fails, it will be because of something else! üôÉ"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "sns.kdeplot(y_train, fill=True, alpha=0.4, color=\"tab:blue\", label=f\"Train ({len(y_train)})\")\n",
    "sns.kdeplot(y_test,  fill=True, alpha=0.4, color=\"tab:orange\", label=f\"Test ({len(y_test)})\")\n",
    "sns.rugplot(y_train)\n",
    "sns.rugplot(y_test)\n",
    "plt.xlabel('LogS')\n",
    "plt.legend()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Looking deeper into our representation\n",
    "\n",
    "One thing we can do as an explorative analysis, is to briefly see what the model sees.\n",
    "\n",
    "Currently, the `X_train` variable is just a vector of 0s and 1s.\n",
    "\n",
    "We retrieve the meta data of each bit (i.e., the environment) and we use the molecular graph of the molecules to construct the substructure encoded in each bit."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- build list of molecules from SMILES ---\n",
    "smiles_list = split['train']['Drug'].tolist()\n",
    "mols = [Chem.MolFromSmiles(smi) for smi in smiles_list]\n",
    "\n",
    "# --- collect bitInfo for each mol ---\n",
    "bitinfos = []\n",
    "for mol in mols:\n",
    "    info = {}\n",
    "    # radius must match your fingerprint generator (e.g. 2 for Morgan radius=2)\n",
    "    _ = AllChem.GetMorganFingerprintAsBitVect(\n",
    "        mol,\n",
    "        radius=2,\n",
    "        nBits=X_train.shape[1],\n",
    "        bitInfo=info\n",
    "    )\n",
    "    bitinfos.append(info)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1- How frequent are the bits?\n",
    "\n",
    "The below figure show the percentage of molecules that activated a given bit.\n",
    "\n",
    "There are a few bits that were activated in over 50% of the molecules, but the majority of the bits were active in less than 10% only."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Count number of molecules where each bit is active\n",
    "bit_counts = X_train.sum(axis=0)   # shape: (n_bits,)\n",
    "n_mols = X_train.shape[0]\n",
    "\n",
    "# Convert to percentages\n",
    "bit_percents = (bit_counts / n_mols) * 100\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(np.arange(len(bit_percents)), bit_percents, color=\"steelblue\")\n",
    "plt.xlabel(\"Fingerprint bit index\")\n",
    "plt.ylabel(\"Percentage of molecules activating this bit (%)\")\n",
    "plt.title(\"Bit activity percentages in training set\")\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2- What about collisions?\n",
    "\n",
    "Collisions happen when the encoding of an atom and its environment ends up in the same bit as another atom and environment.\n",
    "\n",
    "--\n",
    "\n",
    "Two atom-environment pairs can map to the same bit **artifitially** as the way to assing an atom-environment identifier (id) to a bit is by getting the mod of `id % nBits` (see the animation).\n",
    "\n",
    "Thus, two ids when divided by the vector length, can yeild the same mod.\n",
    "\n",
    "For example, assume we have these two atom-environment pairs identifiers\n",
    "<br>id1 = 123456\n",
    "<br>id2 = 124480\n",
    "\n",
    "id2 % 1024 = 960\n",
    "<br>id2 % 1024 = 960\n",
    "\n",
    "Both pair activate bit index 960.\n",
    "\n",
    "--\n",
    "\n",
    "But two atom-environment pair can lead to the same bit because they got the same identifier. And this happens when the two pairs are **chemically similar** that their environment infomation led to the same id.\n",
    "\n",
    "--\n",
    "\n",
    "The left plot below looks at each molecule and checks how many atom-environment pairs map to the same bit, and whether it is an artificial collision or chemical collision.\n",
    "\n",
    "The right plot looks at the bits and see how many molecules showed this mapping for this bit, as well as the type of mapping (i.e., artifitial or chemicaly similar)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from collections import defaultdict, Counter\n",
    "import hashlib\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "def get_morgan_env_ids(mol, radius=2, nBits=1024):\n",
    "    \"\"\"\n",
    "    Compute raw 32-bit IDs and folded IDs for all atom environments.\n",
    "    Returns a list of (raw_id, folded_id, atom_idx, radius).\n",
    "    \"\"\"\n",
    "    env_ids = []\n",
    "    invariants = rdMolDescriptors.GetConnectivityInvariants(mol)\n",
    "\n",
    "    for atom_idx in range(mol.GetNumAtoms()):\n",
    "        for rad in range(radius + 1):\n",
    "            env = Chem.FindAtomEnvironmentOfRadiusN(mol, rad, atom_idx)\n",
    "            atoms = {atom_idx}\n",
    "            for b in env:\n",
    "                bond = mol.GetBondWithIdx(b)\n",
    "                atoms.add(bond.GetBeginAtomIdx())\n",
    "                atoms.add(bond.GetEndAtomIdx())\n",
    "\n",
    "            # encode environment string\n",
    "            env_string = \";\".join(f\"{a}:{invariants[a]}\" for a in sorted(atoms)) \\\n",
    "                       + \"|\" + \",\".join(str(b) for b in sorted(env))\n",
    "\n",
    "            # SHA1 ‚Üí 32-bit ID\n",
    "            raw_id = int(hashlib.sha1(env_string.encode(\"utf-8\")).hexdigest(), 16) & 0xFFFFFFFF\n",
    "            folded_id = raw_id % nBits\n",
    "\n",
    "            env_ids.append((raw_id, folded_id, atom_idx, rad))\n",
    "\n",
    "    return env_ids\n",
    "\n",
    "# --- Step 1: per-molecule collision classification ---\n",
    "chem_counts, art_counts = [], []\n",
    "chem_bit_counter, art_bit_counter = Counter(), Counter()\n",
    "\n",
    "for smi in smiles_list:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    env_ids = get_morgan_env_ids(mol, radius=2)  # from earlier helper\n",
    "    folded_map = defaultdict(list)\n",
    "    for raw_id, folded_id, atom_idx, rad in env_ids:\n",
    "        folded_map[folded_id].append(raw_id)\n",
    "\n",
    "    # classify per-molecule collisions\n",
    "    c, a = 0, 0\n",
    "    for bit, raws in folded_map.items():\n",
    "        if len(raws) > 1:\n",
    "            if len(set(raws)) == 1:\n",
    "                c += 1\n",
    "                chem_bit_counter[bit] += 1\n",
    "            else:\n",
    "                a += 1\n",
    "                art_bit_counter[bit] += 1\n",
    "    chem_counts.append(c)\n",
    "    art_counts.append(a)\n",
    "\n",
    "nMols = len(smiles_list)\n",
    "\n",
    "print(f\"Avg chemical duplicates per molecule: {np.mean(chem_counts):.2f}\")\n",
    "print(f\"Avg artificial collisions per molecule: {np.mean(art_counts):.2f}\")\n",
    "\n",
    "# --- Step 2: per-bit percentages ---\n",
    "chem_perc = {b: c/nMols*100 for b,c in chem_bit_counter.items()}\n",
    "art_perc  = {b: c/nMols*100 for b,c in art_bit_counter.items()}\n",
    "all_bits = set(chem_perc) | set(art_perc)\n",
    "totals = {b: chem_perc.get(b,0)+art_perc.get(b,0) for b in all_bits}\n",
    "\n",
    "# Top-k bits\n",
    "k = 10\n",
    "top_bits = sorted(totals, key=totals.get, reverse=True)[:k]\n",
    "chem_vals = [chem_perc.get(b,0) for b in top_bits]\n",
    "art_vals  = [art_perc.get(b,0) for b in top_bits]\n",
    "\n",
    "# --- Step 3: plots ---\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14,5))\n",
    "\n",
    "# (A) Histogram per molecule (collision type distribution)\n",
    "all_counts = np.array(chem_counts + art_counts)\n",
    "bins = np.arange(all_counts.min(), all_counts.max() + 2) - 0.5  # integer bins\n",
    "\n",
    "axs[0].hist(chem_counts, bins=bins,\n",
    "            weights=np.ones_like(chem_counts)*100.0/nMols,\n",
    "            color=\"tab:blue\", alpha=0.7, edgecolor=\"black\", label=\"Chemical duplicates\")\n",
    "axs[0].hist(art_counts, bins=bins,\n",
    "            weights=np.ones_like(art_counts)*100.0/nMols,\n",
    "            color=\"tab:orange\", alpha=0.7, edgecolor=\"black\", label=\"Artificial collisions\")\n",
    "\n",
    "axs[0].set_xlabel(\"Number of colliding bits per molecule\")\n",
    "axs[0].set_ylabel(\"% of molecules\")\n",
    "axs[0].yaxis.set_major_formatter(PercentFormatter())\n",
    "axs[0].set_title(\"Collision types per molecule\")\n",
    "axs[0].legend()\n",
    "\n",
    "# (B) Top-k bits with stacked bars\n",
    "x = np.arange(k)\n",
    "axs[1].bar(x, chem_vals, color=\"tab:blue\", label=\"Chemical duplicates\")\n",
    "axs[1].bar(x, art_vals, bottom=chem_vals, color=\"tab:orange\", label=\"Artificial collisions\")\n",
    "axs[1].set_xticks(x)\n",
    "axs[1].set_xticklabels(top_bits, rotation=90)\n",
    "axs[1].set_ylabel(\"% of molecules with collision\")\n",
    "axs[1].set_xlabel(\"Bit index\")\n",
    "axs[1].set_title(f\"Top {k} colliding bits (by type)\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3- How informative are the bits?\n",
    "\n",
    "Now, each bit is activated in a group of molecules.\n",
    "\n",
    "One can have a quick idea about the functionality of this bit by checking the solubility distribution of the moelcules activated by it.\n",
    "\n",
    "--\n",
    "\n",
    "If these molecules have a very close values (i.e., small variance), then this bit is likely informative to predict this solubility range.\n",
    "\n",
    "--\n",
    "\n",
    "In the below image, we see the most frquent bits in our dataset shown as the bars.\n",
    "\n",
    "Then a second plot is overlayed that shows the mean and standard deviation of the molecules activated by this bit.\n",
    "\n",
    "We can already see that the ranges are very wide per bit, and that most groups have similar ranges.\n",
    "\n",
    "--\n",
    "\n",
    "An exception is bit 366 where the values show to be noticeably lower that the other ones.\n",
    "\n",
    "However, the overall trend tells us that there seem to not be a single bit that gives us a lot of information immediately."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import numpy as np\n",
    "\n",
    "# Count how many molecules activate each bit\n",
    "bit_counts = X_train.sum(axis=0)\n",
    "n_mols = X_train.shape[0]\n",
    "\n",
    "# Top-k bits (same ranking since percentage = count / n_mols)\n",
    "k = 50\n",
    "top_idx = np.argsort(-bit_counts)[:k]\n",
    "top_counts = bit_counts[top_idx]\n",
    "\n",
    "# Sort descending for nice order\n",
    "sorted_idx = np.argsort(-top_counts)\n",
    "top_idx = top_idx[sorted_idx]\n",
    "top_percents = (top_counts[sorted_idx] / n_mols) * 100\n",
    "\n",
    "# ---- compute mean ¬± sigma of y for the \"bit=1\" group, in the same order ----\n",
    "means_on = []\n",
    "stds_on = []\n",
    "for b in top_idx:\n",
    "    mask = X_train[:, b].astype(bool)\n",
    "    y_on = y_train[mask]\n",
    "    if y_on.size == 0:\n",
    "        means_on.append(np.nan)\n",
    "        stds_on.append(np.nan)\n",
    "    else:\n",
    "        means_on.append(np.nanmean(y_on))\n",
    "        # use ddof=1 for sample std if n>=2, else 0\n",
    "        stds_on.append(np.nanstd(y_on, ddof=1) if y_on.size > 1 else 0.0)\n",
    "\n",
    "means_on = np.array(means_on, dtype=float)\n",
    "stds_on  = np.array(stds_on, dtype=float)\n",
    "\n",
    "x = np.arange(k)\n",
    "\n",
    "# ---- plot: bars (percent) on left axis + mean¬±sigma line on right axis ----\n",
    "fig, ax1 = plt.subplots(figsize=(12,5))\n",
    "bars = ax1.bar(x, top_percents, color=\"steelblue\", label=\"% bit=1\")\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(top_idx, rotation=90)\n",
    "ax1.set_xlabel(\"Fingerprint bit index\")\n",
    "ax1.set_ylabel(\"Percentage of molecules activating this bit\")\n",
    "ax1.yaxis.set_major_formatter(PercentFormatter())\n",
    "ax1.set_title(f\"Top {k} most frequent fingerprint bits (sorted, %) + mean(y|bit=1) ¬± œÉ\")\n",
    "\n",
    "# Secondary axis for continuous y\n",
    "ax2 = ax1.twinx()\n",
    "line, = ax2.plot(x, means_on, marker=\"o\", linewidth=1.6, label=\"mean(y | bit=1)\")\n",
    "band = ax2.fill_between(x, means_on - stds_on, means_on + stds_on, alpha=0.4, label=\"¬±1œÉ\")\n",
    "\n",
    "ax2.set_ylabel(\"y (mean ¬± œÉ for molecules with bit=1)\")\n",
    "\n",
    "# Legends: combine handles from both axes\n",
    "handles1, labels1 = ax1.get_legend_handles_labels()\n",
    "handles2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(handles1 + handles2, labels1 + labels2, loc=\"upper left\")\n",
    "\n",
    "# Add headroom so images/titles don‚Äôt collide (optional)\n",
    "ymax_pct = top_percents.max() if top_percents.size else 0\n",
    "ax1.set_ylim(0, ymax_pct * 1.5 if ymax_pct > 0 else 1)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4- What are the bits?\n",
    "\n",
    "Below we show the atom-environment pairs that have activated the different bits.\n",
    "\n",
    "We show the most freuquent bits"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "import io\n",
    "from PIL import Image as PilImage\n",
    "\n",
    "# --- Helper: convert RDKit Mol to PIL image with atom indices and highlight ---\n",
    "def mol_to_img_with_highlight(mol, center_atom, size=(200,200)):\n",
    "    drawer = rdMolDraw2D.MolDraw2DCairo(size[0], size[1])\n",
    "    opts = drawer.drawOptions()\n",
    "    opts.addAtomIndices = True\n",
    "    opts.bondLineWidth = 2\n",
    "    opts.padding = 0.05\n",
    "\n",
    "    # make all atoms gray by default\n",
    "    opts.useBWAtomPalette()\n",
    "\n",
    "    # highlight center atom in bright yellow\n",
    "    atom_colors = {center_atom: (1.0, 1.0, 0.0)}\n",
    "\n",
    "    rdMolDraw2D.PrepareAndDrawMolecule(\n",
    "        drawer, mol, highlightAtoms=[center_atom], highlightAtomColors=atom_colors\n",
    "    )\n",
    "    drawer.FinishDrawing()\n",
    "    return PilImage.open(io.BytesIO(drawer.GetDrawingText()))\n",
    "\n",
    "\n",
    "# --- Helper: overlay molecule image above a bar ---\n",
    "def add_mol_image(ax, mol, center_atom, x, y, zoom=0.4):\n",
    "    if mol is None:\n",
    "        return\n",
    "    img = mol_to_img_with_highlight(mol, center_atom=center_atom, size=(180,180))\n",
    "    im = OffsetImage(img, zoom=zoom)\n",
    "    ab = AnnotationBbox(im, (x,y), frameon=False, xybox=(0,40),\n",
    "                        xycoords='data', boxcoords=\"offset points\", pad=0)\n",
    "    ax.add_artist(ab)\n",
    "\n",
    "# --- Main function: plot top-k bits with representative substructures ---\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "def plot_bits_with_substructures(X, mols, bitinfos, start=0, k=10):\n",
    "    n_mols = X.shape[0]\n",
    "    bit_counts = X.sum(axis=0)\n",
    "\n",
    "    # Rank all bits by frequency (descending)\n",
    "    all_idx = np.argsort(-bit_counts)\n",
    "    all_counts = bit_counts[all_idx]\n",
    "\n",
    "    # Select window [start : start+k]\n",
    "    top_idx = all_idx[start:start+k]\n",
    "    top_counts = all_counts[start:start+k]\n",
    "    top_percents = (top_counts / n_mols) * 100.0\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    x = range(k)\n",
    "    ax.bar(x, top_percents, color=\"steelblue\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(top_idx, rotation=90)\n",
    "    ax.set_xlabel(\"Fingerprint bit index\")\n",
    "    ax.set_ylabel(\"Percentage of molecules activating this bit\")\n",
    "    ax.set_title(f\"Bits ranked {start+1}‚Äì{start+k} with representative substructures (% of molecules)\")\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter())\n",
    "\n",
    "    if top_percents.max() < 1:\n",
    "      from matplotlib.ticker import FuncFormatter\n",
    "      ax.yaxis.set_major_formatter(FuncFormatter(lambda v, pos: f\"{v:.2f}\".rstrip('0').rstrip('.') + '%'))\n",
    "    # Increase y-limit for images\n",
    "    ylim_max = (top_percents.max() if len(top_percents) else 0) * 1.5\n",
    "    ax.set_ylim(0, ylim_max if ylim_max > 0 else 1)\n",
    "\n",
    "    # Overlay substructure images at % heights\n",
    "    for i, bit in enumerate(top_idx):\n",
    "        for mol, info in zip(mols, bitinfos):\n",
    "            if bit in info:\n",
    "                atom_idx, rad = info[bit][0]\n",
    "                env = Chem.FindAtomEnvironmentOfRadiusN(mol, rad, atom_idx)\n",
    "                if not env:  # expand to radius=1 if empty\n",
    "                    env = Chem.FindAtomEnvironmentOfRadiusN(mol, 1, atom_idx)\n",
    "                atom_map = {}\n",
    "                submol = Chem.PathToSubmol(mol, env, atomMap=atom_map)\n",
    "                center_atom_submol = atom_map.get(atom_idx, 0)\n",
    "                add_mol_image(ax, submol, center_atom=center_atom_submol, x=i, y=top_percents[i])\n",
    "                break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Usage ---\n",
    "k = 10\n",
    "plot_bits_with_substructures(X_train, mols, bitinfos, k=k)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And the least frequent bits"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_bits_with_substructures(X_train, mols, bitinfos, start=nBits-k, k=k)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Random forest regression\n",
    "\n",
    "We have spent quite the time with the data and we have been seeing the molecular world by the eyes of our model.\n",
    "\n",
    "Now, its time to give the space for our model to learn!\n",
    "\n",
    "We will use a simple non-linear model that will try to figure out how to arrange, subset, and manouver these bits to make sensible predictions."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test (MSE): {mse}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Understanding the performance\n",
    "\n",
    "Above, the Mean Squared Error (MSE) is printed, and it's 1.82 LogS.\n",
    "\n",
    "But honestly, this value is quite cryptic! One can do more to make performance easier to understand.\n",
    "\n",
    "Below, we show two plots.\n",
    "\n",
    "\n",
    "\n",
    "1.   The top one is the distributions of the predicted and the true values. And this plot shows that the model captured the width of the true value to some extent. But, it was more keen to make predictions at the center of the distribution.\n",
    "2.   The bottom plot shows the alignment betwen predicitons and truth with varying metrics.\n",
    "  - The pearson correlation (r) measures whether a model captured the trend in the data.\n",
    "    - range = [-1, 1]\n",
    "    - The higher the value the better.\n",
    "    - Here, it is quite high (this is shown by the semi linear shape the scatter plot has)\n",
    "  - The coeffecient of detemination ($R^2$) metric measures how much of the variance is explained.\n",
    "    - Range = (-‚àû, 1]\n",
    "    - The higher the value the better\n",
    "    - Here, it is also a bit high (look at the distributions, they have quite a similar shape)\n",
    "  - The mean absolute error (MAE) measures how far the predictions were from the truth regardless of the direction (i.e., doesn't matter if it over or under-predicts).\n",
    "    - Range is data dependant\n",
    "    - Interpretable by an endpoint expert\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- Shared helper ----\n",
    "def compute_metrics(yp, yt):\n",
    "    \"\"\"Return r, R¬≤, MAE, RMSE for predicted vs true arrays.\"\"\"\n",
    "    if yp.size < 2:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    r = np.corrcoef(yp, yt)[0, 1]\n",
    "    ss_res = np.sum((yt - yp) ** 2)\n",
    "    ss_tot = np.sum((yt - yt.mean()) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot if ss_tot > 0 else np.nan\n",
    "    mae = np.mean(np.abs(yt - yp))\n",
    "    rmse = np.sqrt(np.mean((yt - yp) ** 2))\n",
    "    return r, r2, mae, rmse\n",
    "\n",
    "\n",
    "# ---- Plot distributions + scatter ----\n",
    "def plot_distributions_and_scatter(y_pred, y_test):\n",
    "    mask = np.isfinite(y_pred) & np.isfinite(y_test)\n",
    "    yp, yt = np.asarray(y_pred)[mask], np.asarray(y_test)[mask]\n",
    "\n",
    "    r, r2, mae, rmse = compute_metrics(yp, yt)\n",
    "\n",
    "    lo = min(yp.min(), yt.min())\n",
    "    hi = max(yp.max(), yt.max())\n",
    "    bins = np.histogram_bin_edges(np.concatenate([yt, yp]), bins=\"auto\")\n",
    "\n",
    "    fig, (ax_top, ax_bottom) = plt.subplots(2, 1, figsize=(7, 10), constrained_layout=True)\n",
    "\n",
    "    # (Top) distributions\n",
    "    ax_top.hist(yt, bins=bins, alpha=0.6, label=\"True\", edgecolor=\"black\", linewidth=0.5)\n",
    "    ax_top.hist(yp, bins=bins, alpha=0.6, label=\"Pred\", edgecolor=\"black\", linewidth=0.5)\n",
    "    ax_top.set_title(\"True vs Predicted Distributions\")\n",
    "    ax_top.set_xlabel(\"y\")\n",
    "    ax_top.set_ylabel(\"Count\")\n",
    "    ax_top.legend()\n",
    "    ax_top.grid(True, alpha=0.2)\n",
    "\n",
    "    # (Bottom) scatter\n",
    "    ax_bottom.scatter(yp, yt, s=12, alpha=0.7)\n",
    "    ax_bottom.plot([lo, hi], [lo, hi], 'r--', linewidth=1)\n",
    "    ax_bottom.set_xlabel(\"predicted value\")\n",
    "    ax_bottom.set_ylabel(\"true value\")\n",
    "    ax_bottom.set_title(\"Predicted vs. True\")\n",
    "    ax_bottom.set_xlim(lo, hi)\n",
    "    ax_bottom.set_ylim(lo, hi)\n",
    "    ax_bottom.grid(True, alpha=0.2)\n",
    "\n",
    "    # metrics annotation\n",
    "    text = f\"r = {r:.3f}\\nR¬≤ = {r2:.3f}\\nMAE = {mae:.3f}\"\n",
    "    ax_bottom.text(0.02, 0.98, text, transform=ax_bottom.transAxes,\n",
    "                   ha='left', va='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, linewidth=0.5))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_distributions_and_scatter(y_pred, y_test)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What about practicality?\n",
    "\n",
    "Usually, people in pharma do not interact with molecules in the full ranges of -12 to 2 LogS, but rather, in the range of -6 to -3 [[Ash *et. al.*, 2025]](https://pubs.acs.org/doi/10.1021/acs.jcim.5c01609) (i.e., between micro and milli mole/litre).\n",
    "\n",
    "So, If a pharmacist uses this model, they will be mostly interested in predictions in this practical range. So, Howe does our model perform there?\n",
    "\n",
    "The below figure shows the overall performance but highlights the practical range.\n",
    "\n",
    "One can see from the highlighted part that the predictions are quite scattered.\n",
    "\n",
    "By looking at the metrics:\n",
    "- The pearson correlation r dropped almost by half\n",
    "- The $R^2$ dropped dramatically to below zero\n",
    "- The MAE remained almost the same.\n",
    "\n",
    "How to interpret these differences?\n",
    "- If the pharmacist was already satisfied with a margin of error of 0.9 LogS, then nothing changes.\n",
    "- If the pharmacist is interested in predicting the true values as close as possible, then $R^2$ is saying that this is currently not possible. The model is not good at predicting a correct value at this range.\n",
    "- But r is saying that, while the model is not predicting the exact true value, it still somewhat learns the trend (i.e., when a molecule will be more vs. less soluble)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---- Plot scatter with highlighted practical range ----\n",
    "def plot_scatter_with_range(y_pred, y_test, low=-6, high=-3):\n",
    "    mask = np.isfinite(y_pred) & np.isfinite(y_test)\n",
    "    yp, yt = np.asarray(y_pred)[mask], np.asarray(y_test)[mask]\n",
    "\n",
    "    r, r2, mae, rmse = compute_metrics(yp, yt)\n",
    "\n",
    "    mask_range = (yt >= low) & (yt <= high)\n",
    "    yp_sub, yt_sub = yp[mask_range], yt[mask_range]\n",
    "    r_s, r2_s, mae_s, rmse_s = compute_metrics(yp_sub, yt_sub)\n",
    "\n",
    "    lo = min(yp.min(), yt.min())\n",
    "    hi = max(yp.max(), yt.max())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6.8, 6.2))\n",
    "    ax.axhspan(low, high, facecolor='tab:orange', alpha=0.08, zorder=0)\n",
    "\n",
    "    ax.scatter(yp, yt, s=10, alpha=0.25, color='0.55', label=f'All (n={len(yt)})')\n",
    "    ax.scatter(yp_sub, yt_sub, s=22, alpha=0.9, color='tab:orange',\n",
    "               edgecolor='k', linewidth=0.3,\n",
    "               label=f'In range [{low}, {high}] (n={len(yt_sub)})')\n",
    "\n",
    "    ax.plot([lo, hi], [lo, hi], 'r--', linewidth=1, label='y = x')\n",
    "\n",
    "    ax.set_xlabel('predicted value')\n",
    "    ax.set_ylabel('true value')\n",
    "    ax.set_title('Predicted vs. True (highlighted practical TRUE range)')\n",
    "    ax.set_xlim(lo, hi)\n",
    "    ax.set_ylim(lo, hi)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "\n",
    "    text = (\n",
    "        f\"Overall (n={len(yt)}):\\n\"\n",
    "        f\" r = {r:.3f}   R¬≤ = {r2:.3f}\\n\"\n",
    "        f\" MAE = {mae:.3f}   RMSE = {rmse:.3f}\\n\"\n",
    "        f\"\\nSubset [{low}, {high}] (n={len(yt_sub)}):\\n\"\n",
    "        f\" r = {r_s:.3f}   R¬≤ = {r2_s:.3f}\\n\"\n",
    "        f\" MAE = {mae_s:.3f} \"\n",
    "    )\n",
    "    ax.text(0.02, 0.98, text, transform=ax.transAxes,\n",
    "            ha='left', va='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.85, linewidth=0.5))\n",
    "\n",
    "    ax.legend(loc='lower right', frameon=True, framealpha=0.85)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_scatter_with_range(y_pred, y_test, low=-6, high=-3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Interpreting the forest\n",
    "\n",
    "The random forest algorithm is cool in the sense that it can assign an importance value for each bit.\n",
    "\n",
    "This depends on how much each bit helped in reducing the variability in the data when used for splitting.\n",
    "\n",
    "The below figure shows the most informative bits and displays their atom and environment as well for clarity."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_top_rf_bits_with_substructures(importances, bit_idx, mols, bitinfos, k=10):\n",
    "    order = np.argsort(importances)[::-1]\n",
    "    top_idx = order[:k]\n",
    "    top_bits = bit_idx[top_idx]\n",
    "    top_imps = importances[top_idx]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    x = range(k)\n",
    "    ax.bar(x, top_imps, color=\"darkorange\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(top_bits, rotation=90)\n",
    "    ax.set_xlabel(\"Morgan bit index\")\n",
    "    ax.set_ylabel(\"RF feature importance\")\n",
    "    ax.set_title(f\"Top {k} RF feature importances (Morgan bits)\")\n",
    "\n",
    "    ylim_max = (top_imps.max() if len(top_imps) else 0) * 1.3\n",
    "    ax.set_ylim(0, ylim_max if ylim_max > 0 else 1)\n",
    "\n",
    "    # Try to overlay substructure images\n",
    "    for i, bit in enumerate(top_bits):\n",
    "        placed = False\n",
    "        for mol, info in zip(mols, bitinfos):\n",
    "            if bit in info:\n",
    "                atom_idx, rad = info[bit][0]\n",
    "                env = Chem.FindAtomEnvironmentOfRadiusN(mol, rad, atom_idx)\n",
    "                if not env:  # fallback if lone atom\n",
    "                    env = Chem.FindAtomEnvironmentOfRadiusN(mol, 1, atom_idx)\n",
    "\n",
    "                atom_map = {}\n",
    "                submol = Chem.PathToSubmol(mol, env, atomMap=atom_map)\n",
    "\n",
    "                if atom_idx in atom_map:  # ‚úÖ only highlight if mapping exists\n",
    "                    center_atom_submol = atom_map[atom_idx]\n",
    "                    add_mol_image(ax, submol, center_atom=center_atom_submol,\n",
    "                                  x=i, y=top_imps[i])\n",
    "                    placed = True\n",
    "                    break\n",
    "        if not placed:\n",
    "            print(f\"‚ö†Ô∏è Skipping bit {bit} (could not map atom index)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Usage ---\n",
    "importances = rf_model.feature_importances_\n",
    "bit_idx = np.arange(X_train.shape[1])\n",
    "\n",
    "plot_top_rf_bits_with_substructures(importances, bit_idx, mols, bitinfos, k=10)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Closing the circle - going back to feature analysis\n",
    "\n",
    "At the beginning, we spent quite the time looking at the data and seeing the world through the eyes of the model.\n",
    "\n",
    "Is there direct mappings between the way we interpreted the model's world, and the way the model intepreted it?\n",
    "\n",
    "--\n",
    "\n",
    "We already had a plot that showes the variance in LogS values per activated bit. And we hoped to see some bits that would have highly soluble or highly insluble molecules, then they will be quite informaive ones.\n",
    "\n",
    "But we did not really find many of such bits.\n",
    "\n",
    "--\n",
    "\n",
    "Now, the RF importance assignment is the equivelant of our variance analysis.\n",
    "\n",
    "We can check whether there was any correlation betwen our thinking and the model's thinking.\n",
    "\n",
    "The below plot shows for each bit the variance of the molecules that activated it vs. the imporntance assigned to it by the RF algorithm.\n",
    "\n",
    "I would hope that bits with low variance correlate with high importance by the model.\n",
    "\n",
    "--\n",
    "\n",
    "And while the correlation did not show up. At least we see that the most informative features were more on the left side of the plot (i.e., the part with smaller variance)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: compute variance per bit ---\n",
    "bit_variances = {}\n",
    "for b in range(X_train.shape[1]):\n",
    "    mask = X_train[:, b].astype(bool)\n",
    "    y_on = y_train[mask]\n",
    "    if y_on.size > 1:\n",
    "        bit_variances[b] = np.var(y_on, ddof=1)   # sample variance\n",
    "    else:\n",
    "        bit_variances[b] = np.nan\n",
    "\n",
    "# --- Step 2: collect into dataframe with importances ---\n",
    "bit_idx = np.arange(X_train.shape[1])\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"bit\": bit_idx,\n",
    "    \"importance\": importances,\n",
    "    \"variance\": [bit_variances[b] for b in bit_idx]\n",
    "}).dropna(subset=[\"variance\"])\n",
    "\n",
    "# --- Step 3: rank both dimensions ---\n",
    "df[\"importance_rank\"] = df[\"importance\"].rank(ascending=False, method=\"min\")\n",
    "df[\"variance_rank\"]   = df[\"variance\"].rank(ascending=True, method=\"min\")\n",
    "\n",
    "# --- Step 4: define overlap sets ---\n",
    "top_importance = df.nsmallest(20, \"importance_rank\")\n",
    "low_variance   = df.nsmallest(20, \"variance_rank\")\n",
    "intersection   = pd.merge(top_importance, low_variance, on=\"bit\", suffixes=(\"_imp\", \"_var\"))\n",
    "\n",
    "print(\"Bits that are both high-importance and low-variance:\")\n",
    "print(intersection[[\"bit\", \"importance_imp\", \"variance_imp\",\n",
    "                    \"importance_rank_imp\", \"variance_rank_imp\"]])\n",
    "\n",
    "# --- Step 5: scatter plot ---\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(df[\"variance\"], df[\"importance\"], s=14, alpha=0.6, label=\"All bits\")\n",
    "if not intersection.empty:\n",
    "    plt.scatter(intersection[\"variance\"], intersection[\"importance\"],\n",
    "                color=\"red\", s=40, label=\"Top importance & low variance\")\n",
    "\n",
    "plt.xlabel(\"Variance of y | bit=1\")\n",
    "plt.ylabel(\"RF Feature Importance\")\n",
    "plt.title(\"Importance vs Variance of Morgan bits\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "In the lecture, you got exposed to many algorithms and models that one can pick and try. However, most of this notebook was about looking deeper at the steps of training a model including:\n",
    "- Seeing the world through the eyes of the model\n",
    "- Trying to anticipate in advance what is helpful and what is not\n",
    "- Spending time and effort to contextualize the model's ouput through\n",
    "  - Proper performance visualization\n",
    "  - Interpretability analysis\n",
    "  - Practicality lense\n",
    "- Finally, going back to where we started to see how much were we accurate in our preliminary assumptions.\n",
    "\n",
    "Using an ML library and training a model is an extremely simple thing nowadays.\n",
    "\n",
    "But this is probably not the goal!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# More hands-on notebooks?\n",
    "\n",
    "Check out the [TeachOpenCADD](https://volkamerlab.org/projects/teachopencadd/) collection from the Volkamer lab!\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " # More philosophically-driven hands-on?\n",
    "\n",
    "Check [The diaries of a cheminformatics PhD](https://afnan-sultan.github.io/year-archive/) blog by me, Afnan Sultan!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Supplementary material - More models!\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Neural networks\n",
    "\n",
    "### Multi-layer perceptron (MLP) on fingerprints"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tqdm\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SolubilityDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        self.fingerprints = torch.tensor(list(map(smiles2fp, split['Drug'])), dtype=torch.float)\n",
    "        self.labels = torch.tensor(split['Y'], dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fingerprint = self.fingerprints[idx]\n",
    "        label = self.labels[idx]\n",
    "        return fingerprint, label\n",
    "\n",
    "train_dataset = SolubilityDataset(split['train'])\n",
    "valid_dataset = SolubilityDataset(split['valid'])\n",
    "test_dataset = SolubilityDataset(split['test'])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SolubilityNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SolubilityNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SolubilityNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train_step(loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for fingerprints, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(fingerprints)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(labels)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def test_step(loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for fingerprints, labels in valid_dataloader:\n",
    "            outputs = model(fingerprints)\n",
    "            valid_loss += criterion(outputs.squeeze(), labels).item()\n",
    "    valid_loss /= len(valid_dataloader)\n",
    "    return valid_loss\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_step(train_dataloader)\n",
    "    valid_loss = test_step(valid_dataloader)\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:03d}, Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for fingerprints, labels in test_dataloader:\n",
    "            outputs = model(fingerprints)\n",
    "            test_loss += criterion(outputs.squeeze(), labels).item()\n",
    "    test_loss /= len(test_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with torch.no_grad():\n",
    "    plt.scatter(model(test_dataloader.dataset.fingerprints).flatten(), test_dataloader.dataset.labels, marker='.')\n",
    "plt.plot([-10, 2], [-10, 2], 'r--')\n",
    "plt.ylabel('true value')\n",
    "plt.xlabel('predicted value')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Graph neural network (GNN)\n",
    "\n",
    "First, we need to create graph structures out of the SMILES string. For this, we use the from_smiles utility in pytorch-geometric. This way, we create one `Data` object for each molecule. We additionally annotate each molecule with the solubility value (as attribute `y`)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch_geometric.utils import from_smiles\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "def process_smiles(row):\n",
    "    data = from_smiles(row.Drug)\n",
    "    data.x = data.x.to(torch.float)\n",
    "    data.y = torch.tensor(row.Y, dtype=torch.float)\n",
    "    return data\n",
    "\n",
    "train_dataloader = DataLoader(list(map(process_smiles, split['train'].itertuples())), batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(list(map(process_smiles, split['valid'].itertuples())), batch_size=32)\n",
    "test_dataloader = DataLoader(list(map(process_smiles, split['test'].itertuples())), batch_size=32)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's take a look at an example molecule and its pytorch-geometric encoding."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "smiles = split['train']['Drug'][0]\n",
    "Chem.MolFromSmiles(smiles)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This graph is represented as a `Data` object. The nodes and its features are stored in `x` with shape `(n_nodes, n_features)`. The bond structure is given as an adjacency list in `edge_index`. Edge features can be found in `edge_attr`."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = from_smiles(split['train']['Drug'][0])\n",
    "data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The atom featurization uses some basic features with torch-geometric computes using rdkit."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# excerpt from torch_geometrics molecular featurization\n",
    "\n",
    "# for atom in mol.GetAtoms():\n",
    "#     row: List[int] = []\n",
    "#     row.append(x_map['atomic_num'].index(atom.GetAtomicNum()))\n",
    "#     row.append(x_map['chirality'].index(str(atom.GetChiralTag())))\n",
    "#     row.append(x_map['degree'].index(atom.GetTotalDegree()))\n",
    "#     row.append(x_map['formal_charge'].index(atom.GetFormalCharge()))\n",
    "#     row.append(x_map['num_hs'].index(atom.GetTotalNumHs()))\n",
    "#     row.append(x_map['num_radical_electrons'].index(atom.GetNumRadicalElectrons()))\n",
    "#     row.append(x_map['hybridization'].index(str(atom.GetHybridization())))\n",
    "#     row.append(x_map['is_aromatic'].index(atom.GetIsAromatic()))\n",
    "#     row.append(x_map['is_in_ring'].index(atom.IsInRing()))\n",
    "#     xs.append(row)\n",
    "\n",
    "data.x"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch_geometric.nn import global_mean_pool, GCNConv\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as Fun\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU\n",
    "\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "\n",
    "import torch.nn.functional as Fun\n",
    "\n",
    "\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    \"\"\"Graph Isomorphism Network class with 3 GINConv layers and 2 linear layers\"\"\"\n",
    "\n",
    "    def __init__(self, dim_h):\n",
    "        \"\"\"Initializing GIN class\n",
    "\n",
    "        Args:\n",
    "            dim_h (int): the dimension of hidden layers\n",
    "        \"\"\"\n",
    "        super(GIN, self).__init__()\n",
    "\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(9, dim_h), ReLU(), Linear(dim_h, dim_h), ReLU())\n",
    "        )\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(\n",
    "                Linear(dim_h, dim_h), ReLU(), Linear(dim_h, dim_h), ReLU()\n",
    "            )\n",
    "        )\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(\n",
    "                Linear(dim_h, dim_h), ReLU(), Linear(dim_h, dim_h), ReLU()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.lin1 = Linear(dim_h, dim_h)\n",
    "        self.lin2 = Linear(dim_h, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        batch = data.batch\n",
    "\n",
    "        # Node embeddings\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv3(h, edge_index)\n",
    "\n",
    "        # Graph-level readout\n",
    "        h = global_add_pool(h, batch)\n",
    "\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = Fun.dropout(h, p=0.1, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "model = GIN(32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out.squeeze(), data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(train_dataloader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        out = model(data)\n",
    "        loss = criterion(out.squeeze(), data.y)\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss = train()\n",
    "    valid_loss = test(valid_dataloader)\n",
    "    print(f'Epoch: {epoch + 1:03d}, Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        outputs = model(data)\n",
    "        test_loss += criterion(outputs.squeeze(), data.y).item()\n",
    "test_loss /= len(test_dataloader)\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with torch.no_grad():\n",
    "  predictions, ground_truth = list(), list()\n",
    "  for data in test_dataloader:\n",
    "      outputs = model(data)\n",
    "      predictions.extend(list(outputs.squeeze()))\n",
    "      ground_truth.extend(list(data.y))\n",
    "plt.scatter(predictions, ground_truth, marker='.')\n",
    "plt.ylabel('true value')\n",
    "plt.xlabel('predicted value')\n",
    "plt.plot([-10, 2], [-10, 2], 'r--')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
